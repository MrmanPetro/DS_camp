{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "# Text classification: topic modeling \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "## Latent Dirichlet allocation (LDA)\n",
    "\n",
    "</font>\n",
    "\n",
    "Typically used to detect underlying topics in the text documents\n",
    "\n",
    "**Input** : text documents and number of topics \n",
    "<br>\n",
    "**Output**: Distribution of topics for each document (that allows to assign the one with highest probability) and word distribution for each topic \n",
    "\n",
    "**Assumptions**:\n",
    "- Documents with similar topics use similar groups of words \n",
    "- Documents are probability distribution over latent topics \n",
    "- Topics are probability distribution over words\n",
    "\n",
    "\n",
    "<font color = green >\n",
    "\n",
    "### Generative process\n",
    "\n",
    "</font>\n",
    "\n",
    "LDA considers the every document is created the following way:\n",
    "\n",
    "1) Define number of words in the document\n",
    "<br>\n",
    "2) Chose the topic mixture over the fixed set of topics (e.g. 20% of topic 'Financial', 30% of topic 'Computer Science', and 50% of topic 'Sport')\n",
    "<br>\n",
    "3) Generate the words by:\n",
    "<br>\n",
    "   -pick the topic based on document's multinomial distribution \n",
    "<br>\n",
    "   -pick the word based on topic's multinomial distribution \n",
    "\n",
    "<img src = \"topics_modeling2.jpg\" height=500 width= 800 align=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color = green >\n",
    "\n",
    "#### Recall\n",
    "</font>\n",
    "\n",
    "\n",
    "#### Binomial distribution\n",
    "\n",
    "$$p(k/n)\\quad =\\quad C^{ k }_{ n }\\cdot p^{ k }(1-p)^{ n-k }\\quad =\\quad \\frac { n! }{ k!(n-k)! } p^{ k }(1-p)^{ n-k }$$\n",
    "\n",
    "Example: Probability of 6 of 10 for fear coin: \n",
    "$$p(6,4)\\quad =\\quad C^{ 6 }_{ 10 }\\cdot {0.5}^{ 6 }(0.5)^{ 4 }\\quad = 210 \\cdot 0.015625 \\cdot 0.0625 = 0.205078125$$\n",
    "\n",
    "\n",
    "#### Multinomial distribution\n",
    "\n",
    "$$p(n_{ 1 }n_{ 2 }...n_{ k })\\quad =\\quad \\frac { n! }{ n_{ 1 }!n_{ 2 }!...n_{ k }! } p^{ n_{ 1 } }_{ 1 }p^{ n_{ 2 } }_{ 2 }...p^{ n_{ k } }_{ k }$$\n",
    "\n",
    "Example (three outcomes): <br>\n",
    "n = 12 (12 games are played),<br>\n",
    "n1 = 7 (number won by Player A),<br>\n",
    "n2 = 2 (number won by Player B),<br>\n",
    "n3 = 3 (the number drawn),<br>\n",
    "p1 = 0.4 (probability Player A wins)<br>\n",
    "p2 = 0.35(probability Player B wins)<br>\n",
    "p3 = 0.25(probability of a draw)<br>\n",
    "$$p(7,2,3)\\quad =\\quad \\frac {12!}{ 7! \\cdot 2! \\cdot3 ! }  \\cdot 0.4^{7} \\cdot 0.35^{2} \\cdot0.25^{3} = 0.0248$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Maximul Likelihood Estimation\n",
    "    \n",
    "#### Simple sample\n",
    "    \n",
    "</font>\n",
    "\n",
    "Data is factully sampled `Head Tail Head` (101)\n",
    "\n",
    "Let's investigate  parametr `p` the probability of flipping `Head`\n",
    "\n",
    "<!-- <img src = \"MLE.jpg\" height=500 width= 500 align=\"left\"> -->\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.05 0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65\n",
      " 0.7  0.75 0.8  0.85 0.9  0.95 1.  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.68, 0.156, 'MLE')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt \n",
    "p = np.linspace(0,1,21) \n",
    "print (p )\n",
    "data_prob = p**2 * (1-p) \n",
    "plt.scatter (p,  data_prob) \n",
    "plt.xlabel('p ')\n",
    "plt.ylabel('p (data=HTH)')\n",
    "plt.axvline(x=2/3, color='r')\n",
    "plt.text(.68, .156 ,'MLE', fontsize= 16, color = 'r', bbox=dict(facecolor='none', edgecolor='gray', pad=2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have documents (instead of coin flips) and need to find the distributions (instead of `p` for coin sample) s.t. is MLE for data (all documents)\n",
    "\n",
    "**Recall** \n",
    "<br> Known are text documents and number $K$ of topics \n",
    "\n",
    "**Target**:\n",
    "<br>Within all possible topics distribution for all documemnts and all possible words distribution for topics, shoose the one wich maximizes probability of all text documents.\n",
    "\n",
    "**Note:** It is unclear how to iterate over all possible distributions \n",
    "\n",
    "**Approach** :\n",
    "<br>\n",
    "1) Randomly assign each word of each document to $K$ topics \n",
    "<br>\n",
    "2) Iterate the following process till convergence (steady assignments of w to topics) \n",
    "<br>$\\quad$For each document $d$: \n",
    "<br>\n",
    "    $\\quad\\quad\\bullet$ Assume that all topic assignment except current one are correct<br>\n",
    "    $\\quad\\quad\\bullet$ For each word $w$ in $d$: <br>          \n",
    "    $\\quad\\quad\\quad\\quad$  For every topic $t$ compare the the score for hypothesis that w is in this topic $t$:\n",
    "   <br>$\\quad\\quad\\quad\\quad\\quad score (t) =  p(t | d) \\cdot p (w |t),$\n",
    "   here $p(t|d)$ is proportion of all words in d from t,\n",
    "    and $p(w|t)$ is share of word w in topic t.  \n",
    "    <br>$\\quad\\quad\\quad\\quad$ Assign the word w to the topic with max score\n",
    "    <br>$\\quad\\quad\\bullet$ Iterate through all $w$ in $d$:           \n",
    "<br>$\\quad$Iterate through all $d$\n",
    "\n",
    "The results is matrix of distribution of words in topics  \n",
    "\n",
    "Note: \n",
    "- The computed topics are just words distribution, i.e. need to summarize them somehow \n",
    "- Topics distribution over documents are computed being based on words in document and corresponding topics of each word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\petro\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\petro\\anaconda3\\lib\\site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\petro\\anaconda3\\lib\\site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5.0 in c:\\users\\petro\\anaconda3\\lib\\site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\petro\\anaconda3\\lib\\site-packages (from gensim) (6.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n"
     ]
    }
   ],
   "source": [
    "pip install gensim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "## Gensim LDA \n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Define the text documents \n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_a = \"Brocolli is good to eat. My brother likes to eat good brocolli, but not my mother.\"\n",
    "doc_b = \"My mother spends a lot of time driving my brother around to baseball practice.\"\n",
    "doc_c = \"Some health experts suggest that driving may cause increased tension and blood pressure.\"\n",
    "doc_d = \"I often feel pressure to perform well at school, but my mother never seems to drive my brother to do better.\"\n",
    "doc_e = \"Health professionals say that brocolli is good for your health.\"\n",
    "doc_set = [doc_a, doc_b, doc_c, doc_d, doc_e]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Tokenize, clean, and stem\n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brocolli',\n",
       " 'good',\n",
       " 'eat',\n",
       " '.',\n",
       " 'brother',\n",
       " 'like',\n",
       " 'eat',\n",
       " 'good',\n",
       " 'brocolli',\n",
       " ',',\n",
       " 'mother',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_stop  = set(stopwords.words('english'))\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize(doc_set):\n",
    "    texts = []\n",
    "    for doc in doc_set:\n",
    "        # tokenize document string\n",
    "        raw = doc.lower()\n",
    "        tokens = word_tokenize(raw)\n",
    "\n",
    "        # remove stop words from tokens\n",
    "        tokens = [token for token in tokens if token not in en_stop]\n",
    "\n",
    "        # stem tokens\n",
    "        tokens = [p_stemmer.stem(token) for token in tokens]\n",
    "\n",
    "        # add tokens to list\n",
    "        texts.append(tokens)\n",
    "    return texts\n",
    "\n",
    "texts = tokenize(doc_set)\n",
    "texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Convert tokenized documents into a \"id <-> term\" dictionary\n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.corpora.dictionary.Dictionary'> Dictionary(34 unique tokens: [',', '.', 'brocolli', 'brother', 'eat']...)\n",
      "0 ,\n",
      "1 .\n",
      "2 brocolli\n",
      "3 brother\n",
      "4 eat\n",
      "5 good\n",
      "6 like\n",
      "7 mother\n",
      "8 around\n",
      "9 basebal\n",
      "10 drive\n",
      "11 lot\n",
      "12 practic\n",
      "13 spend\n",
      "14 time\n",
      "15 blood\n",
      "16 caus\n",
      "17 expert\n",
      "18 health\n",
      "19 increas\n",
      "20 may\n",
      "21 pressur\n",
      "22 suggest\n",
      "23 tension\n",
      "24 better\n",
      "25 feel\n",
      "26 never\n",
      "27 often\n",
      "28 perform\n",
      "29 school\n",
      "30 seem\n",
      "31 well\n",
      "32 profession\n",
      "33 say\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts) # this is alternative way - without using count vectorizer\n",
    "print (type(dictionary), dictionary)\n",
    "for k,w in dictionary.items():\n",
    "    print (k,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Create gensim corpus\n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "convert tokenized documents into a document-term matrix\n",
      "[(0, 1), (1, 2), (2, 2), (3, 1), (4, 2), (5, 2), (6, 1), (7, 1)]\n",
      "[(1, 1), (3, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)]\n",
      "[(1, 1), (10, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1)]\n",
      "[(0, 1), (1, 1), (3, 1), (7, 1), (10, 1), (21, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1)]\n",
      "[(1, 1), (2, 1), (5, 1), (18, 2), (32, 1), (33, 1)]\n"
     ]
    }
   ],
   "source": [
    "print ('\\nconvert tokenized documents into a document-term matrix')\n",
    "corpus = [dictionary.doc2bow(text) for text in texts] # id and count\n",
    "for item in corpus:\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation: \n",
    "It shows the id of term and how many tiumes it occurs in the doc e.g. \n",
    "- (3, 1) means `brother` occurs once  in the second sentence\n",
    "- (18, 2) means `health` occurs twice in the last sentence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Generate LDA model\n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(\n",
    "    corpus, num_topics=2, id2word=dictionary, passes=20, random_state= 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Review topics \n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.098*\".\" + 0.076*\"brocolli\" + 0.076*\"good\" + 0.055*\"mother\" + 0.055*\"brother\" + 0.054*\"health\" + 0.054*\"eat\" + 0.033*\",\" + 0.033*\"like\" + 0.033*\"spend\" + 0.033*\"time\" + 0.033*\"around\" + 0.033*\"basebal\" + 0.033*\"lot\" + 0.033*\"practic\" + 0.033*\"say\" + 0.033*\"profession\" + 0.032*\"drive\" + 0.011*\"pressur\" + 0.011*\"caus\" + 0.011*\"may\" + 0.011*\"suggest\" + 0.011*\"expert\" + 0.011*\"feel\" + 0.011*\"blood\" + 0.011*\"better\" + 0.011*\"school\" + 0.011*\"tension\" + 0.011*\"well\" + 0.011*\"seem\" + 0.011*\"perform\" + 0.011*\"increas\" + 0.011*\"often\" + 0.011*\"never\"'),\n",
       " (1,\n",
       "  '0.060*\"drive\" + 0.059*\"pressur\" + 0.059*\".\" + 0.036*\",\" + 0.036*\"never\" + 0.036*\"often\" + 0.036*\"increas\" + 0.036*\"perform\" + 0.036*\"seem\" + 0.036*\"well\" + 0.036*\"tension\" + 0.036*\"school\" + 0.036*\"better\" + 0.036*\"blood\" + 0.036*\"feel\" + 0.036*\"expert\" + 0.036*\"suggest\" + 0.036*\"may\" + 0.036*\"caus\" + 0.036*\"health\" + 0.035*\"brother\" + 0.035*\"mother\" + 0.012*\"profession\" + 0.012*\"say\" + 0.012*\"practic\" + 0.012*\"lot\" + 0.012*\"basebal\" + 0.012*\"around\" + 0.012*\"time\" + 0.012*\"spend\" + 0.012*\"good\" + 0.012*\"brocolli\" + 0.012*\"eat\" + 0.012*\"like\"')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics(num_topics=2,num_words=60) # 0.098 means the p (w|t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Classify the new text \n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "get topics:\n",
      "[(0, 0.37417644), (1, 0.6258235)]\n"
     ]
    }
   ],
   "source": [
    "test_doc_list = [\"Some experts suggest that car may cause increased blood pressure. professionals say that brocolli is good \"]\n",
    "test_texts = tokenize(test_doc_list)\n",
    "test_corpus = [dictionary.doc2bow(text) for text in test_texts ]\n",
    "test_doc_topics = ldamodel.get_document_topics(test_corpus)\n",
    "print ('\\nget topics:')\n",
    "for el in test_doc_topics: # loop over all tests in provided list\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Sample of topic modeling on large dataset\n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Load \"News\" data \n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd= os.getcwd()\n",
    "fn=  'Archive/newsgroups'\n",
    "\n",
    "with open(fn, 'rb') as f:\n",
    "    newsgroup_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Review data\n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "len of documents = 2,000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The best group to keep you informed is the Crohn's and Colitis Foundation\\nof America.  I do not know if the UK has a similar organization.  The\\naddress of\\nthe CCFA is \\n\\nCCFA\\n444 Park Avenue South\\n11th Floor\\nNew York, NY  10016-7374\\nUSA\\n\\nThey have a lot of information available and have a number of newsletters.\\n \\nGood Luck.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (type(newsgroup_data))\n",
    "print ('len of documents = {:,}\\n'.format(len(newsgroup_data)))\n",
    "\n",
    "newsgroup_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Define custom vectorizer\n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=20,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "                strip_accents=None, token_pattern='\\\\b\\\\w{3,}\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_words_pattern = r\"\\b\\w{3,}\\b\"\n",
    "vectorizer = CountVectorizer(\n",
    "    min_df=20, \n",
    "    stop_words='english',\n",
    "    token_pattern=three_words_pattern) \n",
    "vectorizer.fit(newsgroup_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Review feratures \n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of features = 902\n",
      "\n",
      "['000', '100', '1990', '1992', '1993', '200', '2nd', '300', '400', '486', '500', '800', 'ability', 'able', 'accept', 'accepted', 'access', 'according', 'actual', 'actually', 'add', 'addition', 'additional', 'address', 'advance', 'advice', 'age', 'ago', 'agree', 'ahead', 'air', 'allow', 'alt', 'america', 'american', 'answer', 'answers', 'anybody', 'apparently', 'appears']\n"
     ]
    }
   ],
   "source": [
    "print ('len of features = {:,}\\n'.format(len(vectorizer.get_feature_names())))\n",
    "print (vectorizer.get_feature_names()[:40])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Vectorize data set\n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 23)\t1\n",
      "  (0, 33)\t1\n",
      "  (0, 58)\t1\n",
      "  (0, 76)\t1\n",
      "  (0, 326)\t1\n",
      "  (0, 335)\t1\n",
      "  (0, 386)\t1\n",
      "  (0, 409)\t1\n",
      "  (0, 451)\t1\n",
      "  (0, 456)\t1\n",
      "  (0, 515)\t1\n",
      "  (0, 529)\t1\n",
      "  (0, 545)\t1\n",
      "  (0, 727)\t1\n",
      "  (0, 843)\t1\n",
      "  (0, 900)\t1\n",
      "  (1, 33)\t1\n",
      "  (1, 34)\t1\n",
      "  (1, 84)\t1\n",
      "  (1, 184)\t1\n",
      "  (1, 201)\t1\n",
      "  (1, 214)\t1\n",
      "  (1, 231)\t2\n",
      "  (1, 241)\t1\n",
      "  (1, 324)\t1\n",
      "  :\t:\n",
      "  (1998, 622)\t1\n",
      "  (1998, 625)\t3\n",
      "  (1998, 688)\t1\n",
      "  (1998, 698)\t2\n",
      "  (1998, 726)\t1\n",
      "  (1998, 804)\t1\n",
      "  (1998, 805)\t1\n",
      "  (1998, 810)\t10\n",
      "  (1998, 813)\t2\n",
      "  (1998, 814)\t1\n",
      "  (1998, 816)\t1\n",
      "  (1998, 818)\t1\n",
      "  (1998, 844)\t1\n",
      "  (1998, 882)\t2\n",
      "  (1998, 899)\t1\n",
      "  (1999, 171)\t1\n",
      "  (1999, 194)\t1\n",
      "  (1999, 205)\t1\n",
      "  (1999, 213)\t1\n",
      "  (1999, 276)\t2\n",
      "  (1999, 308)\t1\n",
      "  (1999, 344)\t1\n",
      "  (1999, 669)\t1\n",
      "  (1999, 832)\t1\n",
      "  (1999, 874)\t1\n"
     ]
    }
   ],
   "source": [
    "newsgroup_data_vectorized= vectorizer.transform(newsgroup_data)\n",
    "print (newsgroup_data_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Create gensim corpus\n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(23, 1),\n",
       "  (33, 1),\n",
       "  (58, 1),\n",
       "  (76, 1),\n",
       "  (326, 1),\n",
       "  (335, 1),\n",
       "  (386, 1),\n",
       "  (409, 1),\n",
       "  (451, 1),\n",
       "  (456, 1),\n",
       "  (515, 1),\n",
       "  (529, 1),\n",
       "  (545, 1),\n",
       "  (727, 1),\n",
       "  (843, 1),\n",
       "  (900, 1)],\n",
       " [(33, 1),\n",
       "  (34, 1),\n",
       "  (84, 1),\n",
       "  (184, 1),\n",
       "  (201, 1),\n",
       "  (214, 1),\n",
       "  (231, 2),\n",
       "  (241, 1),\n",
       "  (324, 1),\n",
       "  (332, 1),\n",
       "  (359, 1),\n",
       "  (363, 1),\n",
       "  (365, 1),\n",
       "  (409, 1),\n",
       "  (430, 3),\n",
       "  (451, 1),\n",
       "  (475, 1),\n",
       "  (492, 2),\n",
       "  (525, 2),\n",
       "  (605, 1),\n",
       "  (633, 2),\n",
       "  (642, 1),\n",
       "  (674, 1),\n",
       "  (688, 1),\n",
       "  (709, 1),\n",
       "  (750, 1),\n",
       "  (777, 1),\n",
       "  (823, 1),\n",
       "  (838, 1),\n",
       "  (874, 1),\n",
       "  (896, 1)],\n",
       " [(25, 1),\n",
       "  (26, 1),\n",
       "  (63, 1),\n",
       "  (120, 1),\n",
       "  (231, 1),\n",
       "  (297, 1),\n",
       "  (326, 1),\n",
       "  (344, 1),\n",
       "  (373, 1),\n",
       "  (423, 1),\n",
       "  (442, 1),\n",
       "  (444, 1),\n",
       "  (448, 2),\n",
       "  (465, 1),\n",
       "  (572, 1),\n",
       "  (653, 1),\n",
       "  (659, 1),\n",
       "  (714, 1),\n",
       "  (777, 1),\n",
       "  (779, 1),\n",
       "  (781, 1),\n",
       "  (818, 1),\n",
       "  (836, 1),\n",
       "  (855, 1),\n",
       "  (890, 1),\n",
       "  (898, 1)],\n",
       " [(4, 1),\n",
       "  (17, 2),\n",
       "  (18, 1),\n",
       "  (22, 1),\n",
       "  (42, 1),\n",
       "  (48, 2),\n",
       "  (68, 1),\n",
       "  (78, 1),\n",
       "  (86, 1),\n",
       "  (94, 1),\n",
       "  (117, 1),\n",
       "  (119, 1),\n",
       "  (122, 1),\n",
       "  (148, 1),\n",
       "  (155, 1),\n",
       "  (169, 1),\n",
       "  (210, 2),\n",
       "  (232, 1),\n",
       "  (242, 7),\n",
       "  (262, 1),\n",
       "  (297, 1),\n",
       "  (348, 2),\n",
       "  (360, 3),\n",
       "  (367, 2),\n",
       "  (374, 1),\n",
       "  (378, 2),\n",
       "  (384, 1),\n",
       "  (386, 4),\n",
       "  (392, 1),\n",
       "  (397, 2),\n",
       "  (403, 1),\n",
       "  (423, 1),\n",
       "  (426, 1),\n",
       "  (438, 1),\n",
       "  (440, 3),\n",
       "  (462, 1),\n",
       "  (466, 1),\n",
       "  (470, 2),\n",
       "  (471, 1),\n",
       "  (483, 1),\n",
       "  (486, 2),\n",
       "  (506, 1),\n",
       "  (509, 1),\n",
       "  (510, 2),\n",
       "  (515, 3),\n",
       "  (553, 2),\n",
       "  (558, 2),\n",
       "  (572, 1),\n",
       "  (588, 2),\n",
       "  (612, 5),\n",
       "  (615, 1),\n",
       "  (616, 1),\n",
       "  (635, 1),\n",
       "  (641, 1),\n",
       "  (646, 1),\n",
       "  (652, 1),\n",
       "  (655, 1),\n",
       "  (688, 2),\n",
       "  (695, 3),\n",
       "  (715, 3),\n",
       "  (727, 1),\n",
       "  (746, 1),\n",
       "  (762, 1),\n",
       "  (765, 1),\n",
       "  (768, 1),\n",
       "  (780, 1),\n",
       "  (793, 1),\n",
       "  (798, 2),\n",
       "  (799, 3),\n",
       "  (818, 1),\n",
       "  (844, 4),\n",
       "  (894, 1),\n",
       "  (901, 2)],\n",
       " [(334, 3), (466, 1)]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = gensim.matutils.Sparse2Corpus(newsgroup_data_vectorized, documents_columns=False)\n",
    "# comparing to using corpora.Dictionary:\n",
    "# corpus = [dictionary.doc2bow(text) for text in texts] \n",
    "[item for item in corpus][:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Create id2word dictionary\n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{76: 'best',\n",
       " 335: 'group',\n",
       " 33: 'america',\n",
       " 409: 'know',\n",
       " 727: 'similar',\n",
       " 545: 'organization',\n",
       " 23: 'address',\n",
       " 515: 'new',\n",
       " 900: 'york',\n",
       " 843: 'usa',\n",
       " 451: 'lot',\n",
       " 386: 'information',\n",
       " 58: 'available',\n",
       " 529: 'number',\n",
       " 326: 'good',\n",
       " 456: 'luck',\n",
       " 750: 'sounds',\n",
       " 430: 'like',\n",
       " 84: 'blood',\n",
       " 359: 'hey',\n",
       " 709: 'send',\n",
       " 231: 'don',\n",
       " 777: 'study',\n",
       " 363: 'history',\n",
       " 525: 'north',\n",
       " 241: 'early',\n",
       " 605: 'probably',\n",
       " 34: 'american',\n",
       " 492: 'mode',\n",
       " 838: 'understand',\n",
       " 201: 'decide',\n",
       " 633: 'reading',\n",
       " 475: 'mean',\n",
       " 688: 'said',\n",
       " 823: 'toronto',\n",
       " 324: 'going',\n",
       " 874: 'win',\n",
       " 184: 'cup',\n",
       " 896: 'yeah',\n",
       " 674: 'right',\n",
       " 642: 'rec',\n",
       " 365: 'hockey',\n",
       " 332: 'great',\n",
       " 214: 'didn',\n",
       " 779: 'stupid',\n",
       " 423: 'leave',\n",
       " 572: 'place',\n",
       " 63: 'bad',\n",
       " 25: 'advice',\n",
       " 465: 'major',\n",
       " 344: 'hard',\n",
       " 448: 'lose',\n",
       " 818: 'time',\n",
       " 442: 'long',\n",
       " 26: 'age',\n",
       " 373: 'hurt',\n",
       " 898: 'years',\n",
       " 297: 'following',\n",
       " 855: 'video',\n",
       " 836: 'type',\n",
       " 120: 'caused',\n",
       " 653: 'relatively',\n",
       " 890: 'worst',\n",
       " 714: 'seriously',\n",
       " 781: 'suggest',\n",
       " 444: 'look',\n",
       " 659: 'replace',\n",
       " 641: 'reasons',\n",
       " 655: 'religious',\n",
       " 148: 'com',\n",
       " 780: 'subject',\n",
       " 4: '1993',\n",
       " 242: 'earth',\n",
       " 715: 'service',\n",
       " 646: 'recently',\n",
       " 17: 'according',\n",
       " 262: 'exists',\n",
       " 652: 'related',\n",
       " 42: 'applications',\n",
       " 471: 'mark',\n",
       " 765: 'statement',\n",
       " 901: 'young',\n",
       " 558: 'people',\n",
       " 510: 'need',\n",
       " 78: 'better',\n",
       " 155: 'common',\n",
       " 119: 'cause',\n",
       " 844: 'use',\n",
       " 438: 'live',\n",
       " 588: 'possible',\n",
       " 348: 'having',\n",
       " 48: 'areas',\n",
       " 615: 'provide',\n",
       " 612: 'program',\n",
       " 384: 'including',\n",
       " 894: 'written',\n",
       " 378: 'ideas',\n",
       " 509: 'necessary',\n",
       " 486: 'middle',\n",
       " 360: 'high',\n",
       " 695: 'school',\n",
       " 799: 'teams',\n",
       " 440: 'local',\n",
       " 18: 'actual',\n",
       " 798: 'team',\n",
       " 768: 'status',\n",
       " 68: 'based',\n",
       " 122: 'certain',\n",
       " 22: 'additional',\n",
       " 746: 'soon',\n",
       " 553: 'particularly',\n",
       " 397: 'involved',\n",
       " 506: 'national',\n",
       " 426: 'level',\n",
       " 210: 'development',\n",
       " 470: 'manual',\n",
       " 793: 'takes',\n",
       " 466: 'make',\n",
       " 616: 'public',\n",
       " 367: 'home',\n",
       " 483: 'message',\n",
       " 86: 'board',\n",
       " 117: 'case',\n",
       " 635: 'real',\n",
       " 462: 'mail',\n",
       " 94: 'box',\n",
       " 392: 'interested',\n",
       " 762: 'starting',\n",
       " 403: 'just',\n",
       " 169: 'contact',\n",
       " 374: 'ibm',\n",
       " 232: 'dos',\n",
       " 334: 'ground',\n",
       " 607: 'problems',\n",
       " 716: 'set',\n",
       " 828: 'transfer',\n",
       " 47: 'area',\n",
       " 172: 'controller',\n",
       " 864: 'way',\n",
       " 606: 'problem',\n",
       " 10: '500',\n",
       " 590: 'post',\n",
       " 566: 'picture',\n",
       " 281: 'fault',\n",
       " 390: 'instead',\n",
       " 317: 'getting',\n",
       " 192: 'dave',\n",
       " 848: 'using',\n",
       " 783: 'sun',\n",
       " 347: 'haven',\n",
       " 711: 'sent',\n",
       " 731: 'single',\n",
       " 337: 'guy',\n",
       " 447: 'looks',\n",
       " 352: 'heard',\n",
       " 167: 'considered',\n",
       " 310: 'gas',\n",
       " 473: 'matter',\n",
       " 144: 'clean',\n",
       " 887: 'works',\n",
       " 116: 'cars',\n",
       " 217: 'different',\n",
       " 55: 'assume',\n",
       " 425: 'let',\n",
       " 351: 'hear',\n",
       " 541: 'opinions',\n",
       " 813: 'think',\n",
       " 270: 'face',\n",
       " 625: 'quite',\n",
       " 194: 'day',\n",
       " 599: 'pretty',\n",
       " 350: 'health',\n",
       " 53: 'ask',\n",
       " 764: 'state',\n",
       " 879: 'won',\n",
       " 399: 'issue',\n",
       " 594: 'power',\n",
       " 756: 'speed',\n",
       " 98: 'btw',\n",
       " 549: 'owner',\n",
       " 57: 'auto',\n",
       " 185: 'current',\n",
       " 111: 'car',\n",
       " 138: 'chris',\n",
       " 469: 'man',\n",
       " 476: 'means',\n",
       " 401: 'job',\n",
       " 446: 'looking',\n",
       " 751: 'source',\n",
       " 421: 'league',\n",
       " 67: 'baseball',\n",
       " 578: 'players',\n",
       " 858: 'want',\n",
       " 436: 'list',\n",
       " 519: 'nice',\n",
       " 663: 'reports',\n",
       " 866: 'week',\n",
       " 228: 'does',\n",
       " 377: 'idea',\n",
       " 175: 'cost',\n",
       " 809: 'thanks',\n",
       " 546: 'original',\n",
       " 621: 'question',\n",
       " 288: 'final',\n",
       " 213: 'did',\n",
       " 477: 'medical',\n",
       " 114: 'care',\n",
       " 651: 'regular',\n",
       " 95: 'break',\n",
       " 356: 'help',\n",
       " 839: 'unfortunately',\n",
       " 857: 'wait',\n",
       " 859: 'wanted',\n",
       " 170: 'continue',\n",
       " 782: 'suggestions',\n",
       " 899: 'yes',\n",
       " 150: 'comes',\n",
       " 30: 'air',\n",
       " 286: 'figure',\n",
       " 75: 'believe',\n",
       " 364: 'hit',\n",
       " 59: 'average',\n",
       " 804: 'terms',\n",
       " 74: 'begin',\n",
       " 488: 'miles',\n",
       " 862: 'wasn',\n",
       " 207: 'designed',\n",
       " 279: 'fast',\n",
       " 523: 'normal',\n",
       " 88: 'body',\n",
       " 206: 'design',\n",
       " 676: 'road',\n",
       " 0: '000',\n",
       " 234: 'drive',\n",
       " 181: 'course',\n",
       " 453: 'love',\n",
       " 79: 'big',\n",
       " 489: 'mind',\n",
       " 393: 'interesting',\n",
       " 452: 'lots',\n",
       " 870: 'west',\n",
       " 753: 'space',\n",
       " 191: 'date',\n",
       " 277: 'faq',\n",
       " 705: 'section',\n",
       " 591: 'posted',\n",
       " 696: 'sci',\n",
       " 852: 'various',\n",
       " 291: 'fine',\n",
       " 406: 'kill',\n",
       " 666: 'requires',\n",
       " 64: 'ball',\n",
       " 314: 'generally',\n",
       " 637: 'really',\n",
       " 778: 'stuff',\n",
       " 300: 'forget',\n",
       " 316: 'gets',\n",
       " 507: 'natural',\n",
       " 544: 'order',\n",
       " 512: 'needs',\n",
       " 480: 'men',\n",
       " 243: 'easily',\n",
       " 846: 'useful',\n",
       " 496: 'money',\n",
       " 508: 'near',\n",
       " 402: 'john',\n",
       " 467: 'makes',\n",
       " 562: 'person',\n",
       " 561: 'period',\n",
       " 648: 'red',\n",
       " 85: 'blue',\n",
       " 311: 'gave',\n",
       " 632: 'read',\n",
       " 89: 'book',\n",
       " 263: 'expect',\n",
       " 322: 'god',\n",
       " 246: 'eat',\n",
       " 802: 'tell',\n",
       " 526: 'note',\n",
       " 182: 'cover',\n",
       " 622: 'questions',\n",
       " 118: 'cases',\n",
       " 1: '100',\n",
       " 725: 'signal',\n",
       " 208: 'details',\n",
       " 82: 'bit',\n",
       " 596: 'pre',\n",
       " 583: 'point',\n",
       " 555: 'pass',\n",
       " 736: 'slightly',\n",
       " 524: 'normally',\n",
       " 380: 'important',\n",
       " 258: 'exactly',\n",
       " 760: 'start',\n",
       " 800: 'technical',\n",
       " 692: 'say',\n",
       " 815: 'thought',\n",
       " 787: 'sure',\n",
       " 328: 'got',\n",
       " 734: 'size',\n",
       " 576: 'played',\n",
       " 12: 'ability',\n",
       " 897: 'year',\n",
       " 829: 'tried',\n",
       " 575: 'play',\n",
       " 19: 'actually',\n",
       " 216: 'difference',\n",
       " 349: 'head',\n",
       " 354: 'hell',\n",
       " 758: 'sports',\n",
       " 707: 'seen',\n",
       " 266: 'experience',\n",
       " 394: 'interface',\n",
       " 845: 'used',\n",
       " 741: 'software',\n",
       " 717: 'setting',\n",
       " 275: 'fan',\n",
       " 37: 'anybody',\n",
       " 518: 'nhl',\n",
       " 130: 'cheap',\n",
       " 720: 'shot',\n",
       " 308: 'game',\n",
       " 463: 'main',\n",
       " 618: 'purpose',\n",
       " 772: 'stop',\n",
       " 604: 'pro',\n",
       " 771: 'stick',\n",
       " 124: 'chance',\n",
       " 571: 'pittsburgh',\n",
       " 307: 'future',\n",
       " 77: 'bet',\n",
       " 891: 'worth',\n",
       " 577: 'player',\n",
       " 657: 'remove',\n",
       " 527: 'notice',\n",
       " 325: 'gone',\n",
       " 164: 'connection',\n",
       " 881: 'wondering',\n",
       " 412: 'knows',\n",
       " 171: 'control',\n",
       " 884: 'work',\n",
       " 834: 'turn',\n",
       " 434: 'line',\n",
       " 694: 'says',\n",
       " 428: 'life',\n",
       " 159: 'complete',\n",
       " 608: 'process',\n",
       " 303: 'free',\n",
       " 215: 'die',\n",
       " 690: 'save',\n",
       " 851: 'value',\n",
       " 199: 'death',\n",
       " 255: 'especially',\n",
       " 712: 'serial',\n",
       " 160: 'completely',\n",
       " 13: 'able',\n",
       " 330: 'government',\n",
       " 639: 'reason',\n",
       " 196: 'dead',\n",
       " 418: 'law',\n",
       " 381: 'include',\n",
       " 681: 'rule',\n",
       " 682: 'rules',\n",
       " 895: 'wrong',\n",
       " 747: 'sorry',\n",
       " 197: 'deal',\n",
       " 740: 'society',\n",
       " 691: 'saw',\n",
       " 389: 'installed',\n",
       " 198: 'dealer',\n",
       " 251: 'email',\n",
       " 450: 'lost',\n",
       " 256: 'european',\n",
       " 742: 'sold',\n",
       " 179: 'country',\n",
       " 341: 'happen',\n",
       " 814: 'thinking',\n",
       " 863: 'watch',\n",
       " 103: 'buy',\n",
       " 611: 'products',\n",
       " 276: 'fans',\n",
       " 145: 'clear',\n",
       " 49: 'aren',\n",
       " 340: 'hand',\n",
       " 3: '1992',\n",
       " 867: 'weeks',\n",
       " 27: 'ago',\n",
       " 656: 'remember',\n",
       " 93: 'bought',\n",
       " 195: 'days',\n",
       " 822: 'took',\n",
       " 83: 'black',\n",
       " 669: 'rest',\n",
       " 429: 'light',\n",
       " 552: 'particular',\n",
       " 745: 'somewhat',\n",
       " 336: 'guess',\n",
       " 610: 'product',\n",
       " 472: 'market',\n",
       " 743: 'solution',\n",
       " 333: 'greatly',\n",
       " 44: 'appreciated',\n",
       " 50: 'argument',\n",
       " 774: 'straight',\n",
       " 854: 'version',\n",
       " 849: 'usual',\n",
       " 810: 'theory',\n",
       " 892: 'wouldn',\n",
       " 811: 'thing',\n",
       " 649: 'reference',\n",
       " 786: 'supposed',\n",
       " 173: 'copy',\n",
       " 61: 'away',\n",
       " 240: 'earlier',\n",
       " 51: 'arguments',\n",
       " 14: 'accept',\n",
       " 796: 'talking',\n",
       " 108: 'called',\n",
       " 697: 'science',\n",
       " 379: 'imagine',\n",
       " 832: 'try',\n",
       " 366: 'hold',\n",
       " 719: 'short',\n",
       " 698: 'scientific',\n",
       " 585: 'poor',\n",
       " 889: 'worse',\n",
       " 202: 'decided',\n",
       " 869: 'went',\n",
       " 710: 'sense',\n",
       " 888: 'world',\n",
       " 856: 'view',\n",
       " 437: 'little',\n",
       " 278: 'far',\n",
       " 411: 'known',\n",
       " 769: 'stay',\n",
       " 539: 'open',\n",
       " 795: 'talk',\n",
       " 142: 'claims',\n",
       " 70: 'basically',\n",
       " 468: 'making',\n",
       " 248: 'edu',\n",
       " 759: 'standard',\n",
       " 146: 'clock',\n",
       " 574: 'plan',\n",
       " 166: 'consider',\n",
       " 136: 'chips',\n",
       " 168: 'considering',\n",
       " 767: 'station',\n",
       " 565: 'pick',\n",
       " 752: 'sources',\n",
       " 820: 'today',\n",
       " 861: 'washington',\n",
       " 419: 'lead',\n",
       " 871: 'white',\n",
       " 81: 'bikes',\n",
       " 80: 'bike',\n",
       " 808: 'thank',\n",
       " 52: 'article',\n",
       " 693: 'saying',\n",
       " 283: 'feel',\n",
       " 398: 'isn',\n",
       " 833: 'trying',\n",
       " 623: 'quick',\n",
       " 230: 'doing',\n",
       " 806: 'tests',\n",
       " 819: 'times',\n",
       " 595: 'practice',\n",
       " 292: 'fit',\n",
       " 850: 'usually',\n",
       " 554: 'parts',\n",
       " 414: 'large',\n",
       " 534: 'office',\n",
       " 318: 'given',\n",
       " 415: 'late',\n",
       " 222: 'disease',\n",
       " 821: 'told',\n",
       " 825: 'town',\n",
       " 20: 'add',\n",
       " 295: 'folks',\n",
       " 407: 'kind',\n",
       " 880: 'wonder',\n",
       " 188: 'damage',\n",
       " 327: 'gordon',\n",
       " 174: 'correct',\n",
       " 766: 'states',\n",
       " 355: 'hello',\n",
       " 183: 'cross',\n",
       " 511: 'needed',\n",
       " 177: 'couldn',\n",
       " 65: 'banks',\n",
       " 504: 'n3jxp',\n",
       " 735: 'skepticism',\n",
       " 129: 'chastity',\n",
       " 391: 'intellect',\n",
       " 312: 'geb',\n",
       " 106: 'cadre',\n",
       " 239: 'dsl',\n",
       " 570: 'pitt',\n",
       " 718: 'shameful',\n",
       " 788: 'surrender',\n",
       " 499: 'months',\n",
       " 536: 'old',\n",
       " 273: 'fairly',\n",
       " 528: 'noticed',\n",
       " 738: 'small',\n",
       " 128: 'charge',\n",
       " 454: 'low',\n",
       " 154: 'commercial',\n",
       " 531: 'obvious',\n",
       " 875: 'windows',\n",
       " 113: 'cards',\n",
       " 497: 'monitor',\n",
       " 162: 'connect',\n",
       " 236: 'drivers',\n",
       " 520: 'night',\n",
       " 579: 'playing',\n",
       " 626: 'radio',\n",
       " 304: 'friend',\n",
       " 521: 'noise',\n",
       " 298: 'food',\n",
       " 427: 'levels',\n",
       " 372: 'human',\n",
       " 522: 'non',\n",
       " 21: 'addition',\n",
       " 812: 'things',\n",
       " 684: 'running',\n",
       " 282: 'fax',\n",
       " 459: 'machine',\n",
       " 441: 'logic',\n",
       " 498: 'month',\n",
       " 229: 'doesn',\n",
       " 302: 'forward',\n",
       " 491: 'minutes',\n",
       " 882: 'word',\n",
       " 287: 'file',\n",
       " 701: 'screen',\n",
       " 193: 'david',\n",
       " 665: 'required',\n",
       " 56: 'atheism',\n",
       " 296: 'follow',\n",
       " 516: 'news',\n",
       " 54: 'asked',\n",
       " 755: 'specific',\n",
       " 801: 'technology',\n",
       " 564: 'phone',\n",
       " 505: 'nasa',\n",
       " 667: 'research',\n",
       " 121: 'center',\n",
       " 329: 'gov',\n",
       " 410: 'knowledge',\n",
       " 748: 'sort',\n",
       " 679: 'room',\n",
       " 36: 'answers',\n",
       " 252: 'end',\n",
       " 178: 'count',\n",
       " 227: 'dod',\n",
       " 598: 'press',\n",
       " 672: 'return',\n",
       " 416: 'later',\n",
       " 433: 'limited',\n",
       " 66: 'base',\n",
       " 613: 'project',\n",
       " 176: 'costs',\n",
       " 264: 'expected',\n",
       " 417: 'launch',\n",
       " 589: 'possibly',\n",
       " 724: 'shuttle',\n",
       " 792: 'taken',\n",
       " 233: 'doubt',\n",
       " 831: 'true',\n",
       " 400: 'jim',\n",
       " 149: 'come',\n",
       " 221: 'discussion',\n",
       " 271: 'fact',\n",
       " 671: 'results',\n",
       " 123: 'certainly',\n",
       " 865: 'ways',\n",
       " 267: 'explain',\n",
       " 218: 'difficult',\n",
       " 112: 'card',\n",
       " 886: 'working',\n",
       " 457: 'lucky',\n",
       " 369: 'hope',\n",
       " 817: 'throw',\n",
       " 290: 'finding',\n",
       " 513: 'net',\n",
       " 45: 'apr',\n",
       " 435: 'lines',\n",
       " 733: 'situation',\n",
       " 211: 'device',\n",
       " 668: 'response',\n",
       " 449: 'loss',\n",
       " 306: 'function',\n",
       " 670: 'result',\n",
       " 96: 'bring',\n",
       " 226: 'doctor',\n",
       " 533: 'offer',\n",
       " 785: 'support',\n",
       " 643: 'recall',\n",
       " 156: 'companies',\n",
       " 708: 'sell',\n",
       " 662: 'report',\n",
       " 556: 'past',\n",
       " 535: 'oil',\n",
       " 683: 'run',\n",
       " 253: 'engine',\n",
       " 455: 'lower',\n",
       " 431: 'likely',\n",
       " 370: 'hot',\n",
       " 205: 'deleted',\n",
       " 841: 'unless',\n",
       " 60: 'avoid',\n",
       " 885: 'worked',\n",
       " 284: 'feet',\n",
       " 323: 'goes',\n",
       " 704: 'second',\n",
       " 551: 'paper',\n",
       " 40: 'apple',\n",
       " 530: 'numbers',\n",
       " 629: 'range',\n",
       " 805: 'test',\n",
       " 158: 'compare',\n",
       " 313: 'general',\n",
       " 109: 'came',\n",
       " 835: 'turned',\n",
       " 339: 'half',\n",
       " 630: 'rangers',\n",
       " 721: 'shouldn',\n",
       " 647: 'record',\n",
       " 739: 'smith',\n",
       " 152: 'comment',\n",
       " 225: 'division',\n",
       " 580: 'playoffs',\n",
       " 245: 'easy',\n",
       " 147: 'close',\n",
       " 254: 'entire',\n",
       " 703: 'season',\n",
       " 309: 'games',\n",
       " 763: 'starts',\n",
       " 204: 'definitely',\n",
       " 132: 'check',\n",
       " 200: 'decent',\n",
       " 289: 'finally',\n",
       " 631: 'rate',\n",
       " 203: 'defense',\n",
       " 71: 'basis',\n",
       " 424: 'left',\n",
       " 501: 'moon',\n",
       " 474: 'maybe',\n",
       " 87: 'bob',\n",
       " 382: 'included',\n",
       " 776: 'student',\n",
       " 102: 'business',\n",
       " 494: 'models',\n",
       " 238: 'driving',\n",
       " 673: 'ride',\n",
       " 137: 'choice',\n",
       " 493: 'model',\n",
       " 602: 'price',\n",
       " 153: 'comments',\n",
       " 92: 'boston',\n",
       " 8: '400',\n",
       " 7: '300',\n",
       " 500: 'montreal',\n",
       " 563: 'philadelphia',\n",
       " 5: '200',\n",
       " 567: 'piece',\n",
       " 728: 'simms',\n",
       " 586: 'port',\n",
       " 104: 'buying',\n",
       " 395: 'internal',\n",
       " 627: 'ram',\n",
       " 280: 'faster',\n",
       " 893: 'write',\n",
       " 220: 'directly',\n",
       " 259: 'example',\n",
       " 775: 'strong',\n",
       " 540: 'opinion',\n",
       " 587: 'position',\n",
       " 640: 'reasonable',\n",
       " 557: 'pay',\n",
       " 387: 'input',\n",
       " 219: 'digital',\n",
       " 161: 'computer',\n",
       " 376: 'ide',\n",
       " 100: 'built',\n",
       " 502: 'motherboard',\n",
       " 702: 'scsi',\n",
       " 265: 'expensive',\n",
       " 237: 'drives',\n",
       " 105: 'cable',\n",
       " 784: 'supply',\n",
       " 481: 'mention',\n",
       " 28: 'agree',\n",
       " 729: 'simple',\n",
       " 614: 'properly',\n",
       " 773: 'story',\n",
       " 730: 'simply',\n",
       " 24: 'advance',\n",
       " 32: 'alt',\n",
       " 824: 'total',\n",
       " 62: 'backup',\n",
       " 791: 'systems',\n",
       " 876: 'wings',\n",
       " 299: 'force',\n",
       " 101: 'bus',\n",
       " 550: 'pain',\n",
       " 636: 'realize',\n",
       " 342: 'happens',\n",
       " 584: 'points',\n",
       " 685: 'runs',\n",
       " 2: '1990',\n",
       " 249: 'effect',\n",
       " 38: 'apparently',\n",
       " 689: 'san',\n",
       " 592: 'posting',\n",
       " 883: 'words',\n",
       " 133: 'cheers',\n",
       " 261: 'exist',\n",
       " 361: 'higher',\n",
       " 235: 'driver',\n",
       " 285: 'field',\n",
       " 837: 'types',\n",
       " 413: 'lack',\n",
       " 180: 'couple',\n",
       " 644: 'received',\n",
       " 503: 'multi',\n",
       " 464: 'maintain',\n",
       " 794: 'taking',\n",
       " 770: 'steve',\n",
       " 803: 'term',\n",
       " 90: 'books',\n",
       " 686: 'safe',\n",
       " 257: 'evidence',\n",
       " 125: 'change',\n",
       " 537: 'older',\n",
       " 538: 'ones',\n",
       " 250: 'effective',\n",
       " 645: 'recent',\n",
       " 634: 'ready',\n",
       " 15: 'accepted',\n",
       " 761: 'started',\n",
       " 548: 'outside',\n",
       " 726: 'significant',\n",
       " 675: 'risk',\n",
       " 478: 'medicine',\n",
       " 190: 'data',\n",
       " 39: 'appears',\n",
       " 97: 'brown',\n",
       " 396: 'internet',\n",
       " 139: 'circuit',\n",
       " 600: 'prevent',\n",
       " 532: 'obviously',\n",
       " 223: 'disk',\n",
       " 678: 'rom',\n",
       " 91: 'boot',\n",
       " 617: 'pull',\n",
       " 422: 'learn',\n",
       " 485: 'michael',\n",
       " 99: 'build',\n",
       " 41: 'application',\n",
       " 790: 'switch',\n",
       " 212: 'devices',\n",
       " 135: 'chip',\n",
       " 754: 'special',\n",
       " 358: 'helps',\n",
       " 723: 'shows',\n",
       " 737: 'slow',\n",
       " 482: 'mentioned',\n",
       " 661: 'reply',\n",
       " 385: 'info',\n",
       " 603: 'prices',\n",
       " 877: 'winning',\n",
       " 143: 'class',\n",
       " 305: 'ftp',\n",
       " 732: 'site',\n",
       " 115: 'carry',\n",
       " 569: 'pins',\n",
       " 495: 'modem',\n",
       " 345: 'hardware',\n",
       " 757: 'spend',\n",
       " 568: 'pin',\n",
       " 141: 'claim',\n",
       " 597: 'present',\n",
       " 789: 'suspect',\n",
       " 609: 'produce',\n",
       " 547: 'output',\n",
       " 699: 'score',\n",
       " 405: 'key',\n",
       " 853: 'vehicle',\n",
       " 388: 'inside',\n",
       " 140: 'city',\n",
       " 31: 'allow',\n",
       " 16: 'access',\n",
       " 35: 'answer',\n",
       " 479: 'memory',\n",
       " 581: 'plug',\n",
       " 165: 'connector',\n",
       " 458: 'mac',\n",
       " 484: 'method',\n",
       " 346: 'hate',\n",
       " 151: 'coming',\n",
       " 375: 'ice',\n",
       " 638: 'rear',\n",
       " 272: 'fair',\n",
       " 244: 'east',\n",
       " 209: 'detroit',\n",
       " 807: 'texas',\n",
       " 134: 'chicago',\n",
       " 107: 'california',\n",
       " 713: 'series',\n",
       " 628: 'ran',\n",
       " 842: 'upgrade',\n",
       " 320: 'giving',\n",
       " 338: 'guys',\n",
       " 593: 'potential',\n",
       " 443: 'longer',\n",
       " 445: 'looked',\n",
       " 46: 'april',\n",
       " 461: 'magazine',\n",
       " 368: 'honda',\n",
       " 654: 'religion',\n",
       " 301: 'form',\n",
       " 383: 'includes',\n",
       " 873: 'willing',\n",
       " 650: 'regards',\n",
       " 517: 'newsgroup',\n",
       " 408: 'knew',\n",
       " 573: 'places',\n",
       " 29: 'ahead',\n",
       " 749: 'sound',\n",
       " 687: 'safety',\n",
       " 487: 'mike',\n",
       " 514: 'network',\n",
       " 847: 'uses',\n",
       " 460: 'machines',\n",
       " 830: 'trouble',\n",
       " 371: 'hours',\n",
       " 319: 'gives',\n",
       " 860: 'wants',\n",
       " 664: 'require',\n",
       " 11: '800',\n",
       " 362: 'highly',\n",
       " 722: 'shown',\n",
       " 744: 'somebody',\n",
       " 357: 'helpful',\n",
       " 43: 'appreciate',\n",
       " 826: 'traffic',\n",
       " 343: 'happy',\n",
       " 620: 'quality',\n",
       " 247: 'edge',\n",
       " 6: '2nd',\n",
       " 560: 'performance',\n",
       " 187: 'cut',\n",
       " 601: 'previous',\n",
       " 680: 'round',\n",
       " 490: 'minor',\n",
       " 268: 'external',\n",
       " 878: 'wish',\n",
       " 9: '486',\n",
       " 315: 'george',\n",
       " 432: 'limit',\n",
       " 163: 'connected',\n",
       " 439: 'load',\n",
       " 624: 'quickly',\n",
       " 353: 'heavy',\n",
       " 126: 'changed',\n",
       " 559: 'perfect',\n",
       " 131: 'cheaper',\n",
       " 260: 'excellent',\n",
       " 269: 'extra',\n",
       " 797: 'tank',\n",
       " 816: 'thread',\n",
       " 110: 'canada',\n",
       " 274: 'family',\n",
       " 619: 'putting',\n",
       " 700: 'scoring',\n",
       " 331: 'graphics',\n",
       " 582: 'plus',\n",
       " 127: 'changes',\n",
       " 840: 'university',\n",
       " 658: 'removed',\n",
       " 872: 'wide',\n",
       " 69: 'basic',\n",
       " 543: 'orbit',\n",
       " 72: 'bay',\n",
       " 157: 'company',\n",
       " 224: 'display',\n",
       " 677: 'robert',\n",
       " 404: 'keeping',\n",
       " 293: 'fixed',\n",
       " 706: 'seeing',\n",
       " 186: 'currently',\n",
       " 321: 'goal',\n",
       " 73: 'beat',\n",
       " 420: 'leafs',\n",
       " 542: 'option',\n",
       " 827: 'training',\n",
       " 868: 'weight',\n",
       " 294: 'floppy',\n",
       " 189: 'damn',\n",
       " 660: 'replacement'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_map = dict((v, k) for k, v in vectorizer.vocabulary_.items()) \n",
    "id_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Generate LDA model\n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel (corpus, num_topics=6, id2word=id_map, passes=25, random_state=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: \n",
    "Comparing to `corpora.Dictionary` use `id2word=id_map` instead of `id2word=dictionary`\n",
    "\n",
    "`ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=2, id2word=dictionary, passes=20, random_state= 0)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Review topics\n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.025*\"edu\" + 0.019*\"com\" + 0.018*\"use\" + 0.018*\"thanks\" + 0.016*\"does\" + 0.015*\"know\" + 0.011*\"mail\" + 0.010*\"apple\" + 0.009*\"help\" + 0.008*\"want\"'),\n",
       " (1,\n",
       "  '0.061*\"drive\" + 0.039*\"disk\" + 0.030*\"scsi\" + 0.027*\"drives\" + 0.027*\"hard\" + 0.025*\"controller\" + 0.021*\"card\" + 0.018*\"rom\" + 0.016*\"cable\" + 0.016*\"floppy\"'),\n",
       " (2,\n",
       "  '0.024*\"people\" + 0.022*\"god\" + 0.012*\"atheism\" + 0.012*\"think\" + 0.012*\"believe\" + 0.012*\"don\" + 0.010*\"does\" + 0.010*\"just\" + 0.009*\"argument\" + 0.009*\"say\"'),\n",
       " (3,\n",
       "  '0.023*\"game\" + 0.021*\"year\" + 0.020*\"team\" + 0.013*\"games\" + 0.013*\"play\" + 0.011*\"good\" + 0.011*\"don\" + 0.010*\"think\" + 0.010*\"season\" + 0.010*\"players\"'),\n",
       " (4,\n",
       "  '0.035*\"space\" + 0.019*\"nasa\" + 0.018*\"data\" + 0.013*\"information\" + 0.013*\"available\" + 0.013*\"center\" + 0.011*\"ground\" + 0.010*\"research\" + 0.010*\"000\" + 0.010*\"new\"'),\n",
       " (5,\n",
       "  '0.017*\"just\" + 0.017*\"like\" + 0.016*\"don\" + 0.012*\"car\" + 0.012*\"time\" + 0.011*\"think\" + 0.011*\"good\" + 0.010*\"know\" + 0.008*\"way\" + 0.008*\"people\"')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics(num_topics=6,num_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Name topics\n",
    "   \n",
    "</font>\n",
    "\n",
    "You need to name the topics manually (or use the top frequent words from topic )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_names= ['Education', 'Computers & IT', 'Religion', 'Sports', 'Science', 'Society & Lifestyle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Classify the new text \n",
    "\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "It's my understanding that the freezing will start to occur because of the\n",
      "growing distance of Pluto and Charon from the Sun, due to it's\n",
      "elliptical orbit. It is not due to shadowing effects. \n",
      "\n",
      "\n",
      "Pluto can shadow Charon, and vice-versa.\n",
      "\n",
      "George Krumins\n",
      "-- \n"
     ]
    }
   ],
   "source": [
    "new_doc = [\"\\n\\nIt's my understanding that the freezing will start to occur because \\\n",
    "of the\\ngrowing distance of Pluto and Charon from the Sun, due to it's\\nelliptical orbit. \\\n",
    "It is not due to shadowing effects. \\n\\n\\nPluto can shadow Charon, and vice-versa.\\n\\nGeorge \\\n",
    "Krumins\\n-- \"] \n",
    "print (new_doc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.033417594),\n",
       "  (1, 0.03334091),\n",
       "  (2, 0.033516586),\n",
       "  (3, 0.033779573),\n",
       "  (4, 0.8323054),\n",
       "  (5, 0.033639915)]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorized= vectorizer.transform(new_doc) # input param is list\n",
    "new_doc_corpus = gensim.matutils.Sparse2Corpus(doc_vectorized, documents_columns=False)\n",
    "doc_topics = ldamodel.get_document_topics(new_doc_corpus)\n",
    "list(doc_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Science'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "def elicit_topic_name(doc_topics):    \n",
    "    return topics_names[np.squeeze(np.array(doc_topics))[:,1].argmax()]\n",
    "elicit_topic_name(doc_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "## Home Task \n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Topic Modeling \n",
    "\n",
    "</font>\n",
    "\n",
    "[voted-kaggle-dataset](https://www.kaggle.com/canggih/voted-kaggle-dataset/version/2#voted-kaggle-dataset.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "fn= 'Archive/voted-kaggle-dataset.csv'\n",
    "df = pd.read_csv(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of texts= 2,150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'These files contain complete loan data for all loans issued through the 2007-2015, including the current loan status (Current, Late, Fully Paid, etc.) and latest payment information. The file containing loan data through the \"present\" contains complete loan data for all loans issued through the previous completed calendar quarter. Additional features include credit scores, number of finance inquiries, address including zip codes, and state, and collections among others. The file is a matrix of about 890 thousand observations and 75 variables. A data dictionary is provided in a separate file. k'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print ('len of texts= {:,}'.format(len(df)))\n",
    "index = 10 \n",
    "df.loc[index, 'Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    The datasets contains transactions made by cre...\n",
       "1    The ultimate Soccer database for data analysis...\n",
       "2    Background\\nWhat can we say about the success ...\n",
       "3    Context\\nInformation on more than 170,000 Terr...\n",
       "4    Context\\nBitcoin is the longest running and mo...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions = df[df['Description'].notnull()]['Description']\n",
    "descriptions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=20,\n",
       "                ngram_range=(1, 1), preprocessor=None,\n",
       "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                            'aren', \"aren't\", 'as', 'at', 'be', 'because',\n",
       "                            'been', 'before', 'being', 'below', 'between',\n",
       "                            'both', 'but', 'by', 'can', 'couldn', \"couldn't\", ...},\n",
       "                strip_accents=None, token_pattern='\\\\b\\\\w{3,}\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english')).union({'data', 'dataset', 'model'})\n",
    "three_words_pattern = r\"\\b\\w{3,}\\b\"\n",
    "vectorizer = CountVectorizer(\n",
    "    min_df=20, \n",
    "    stop_words=stop_words,\n",
    "    token_pattern=three_words_pattern) \n",
    "vectorizer.fit(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of features = 1,872\n",
      "\n",
      "['000', '100', '1000', '1995', '1st', '200', '2000', '2001', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2018', '2nd', '300', '400', '500', '600', 'ability', 'able', 'abs', 'abstract', 'academic', 'access', 'accessed', 'accessible', 'accompanying', 'according', 'account']\n"
     ]
    }
   ],
   "source": [
    "print ('len of features = {:,}\\n'.format(len(vectorizer.get_feature_names())))\n",
    "print (vectorizer.get_feature_names()[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 18)\t1\n",
      "  (0, 20)\t1\n",
      "  (0, 39)\t1\n",
      "  (0, 41)\t2\n",
      "  (0, 98)\t3\n",
      "  (0, 132)\t1\n",
      "  (0, 163)\t1\n",
      "  (0, 168)\t1\n",
      "  (0, 191)\t1\n",
      "  (0, 230)\t1\n",
      "  (0, 237)\t1\n",
      "  (0, 240)\t1\n",
      "  (0, 276)\t1\n",
      "  (0, 283)\t3\n",
      "  (0, 285)\t2\n",
      "  (0, 302)\t1\n",
      "  (0, 343)\t1\n",
      "  (0, 347)\t1\n",
      "  (0, 372)\t3\n",
      "  (0, 399)\t1\n",
      "  (0, 422)\t1\n",
      "  (0, 431)\t1\n",
      "  (0, 439)\t1\n",
      "  (0, 443)\t1\n",
      "  (0, 476)\t1\n",
      "  :\t:\n",
      "  (2143, 1861)\t2\n",
      "  (2144, 8)\t1\n",
      "  (2144, 48)\t1\n",
      "  (2144, 248)\t1\n",
      "  (2144, 249)\t1\n",
      "  (2144, 373)\t1\n",
      "  (2144, 375)\t1\n",
      "  (2144, 382)\t1\n",
      "  (2144, 442)\t3\n",
      "  (2144, 486)\t1\n",
      "  (2144, 503)\t1\n",
      "  (2144, 674)\t1\n",
      "  (2144, 764)\t1\n",
      "  (2144, 852)\t1\n",
      "  (2144, 998)\t1\n",
      "  (2144, 1074)\t3\n",
      "  (2144, 1093)\t2\n",
      "  (2144, 1131)\t3\n",
      "  (2144, 1519)\t2\n",
      "  (2144, 1531)\t1\n",
      "  (2144, 1598)\t1\n",
      "  (2144, 1616)\t1\n",
      "  (2144, 1703)\t1\n",
      "  (2144, 1818)\t2\n",
      "  (2144, 1861)\t2\n"
     ]
    }
   ],
   "source": [
    "descriptions_data_vectorized= vectorizer.transform(descriptions)\n",
    "print (descriptions_data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(18, 1),\n",
       "  (20, 1),\n",
       "  (39, 1),\n",
       "  (41, 2),\n",
       "  (98, 3),\n",
       "  (132, 1),\n",
       "  (163, 1),\n",
       "  (168, 1),\n",
       "  (191, 1),\n",
       "  (230, 1),\n",
       "  (237, 1),\n",
       "  (240, 1),\n",
       "  (276, 1),\n",
       "  (283, 3),\n",
       "  (285, 2),\n",
       "  (302, 1),\n",
       "  (343, 1),\n",
       "  (347, 1),\n",
       "  (372, 3),\n",
       "  (399, 1),\n",
       "  (422, 1),\n",
       "  (431, 1),\n",
       "  (439, 1),\n",
       "  (443, 1),\n",
       "  (476, 1),\n",
       "  (478, 1),\n",
       "  (528, 1),\n",
       "  (589, 1),\n",
       "  (602, 1),\n",
       "  (641, 4),\n",
       "  (642, 3),\n",
       "  (665, 1),\n",
       "  (733, 1),\n",
       "  (753, 1),\n",
       "  (774, 1),\n",
       "  (792, 3),\n",
       "  (806, 1),\n",
       "  (843, 1),\n",
       "  (847, 1),\n",
       "  (861, 1),\n",
       "  (881, 1),\n",
       "  (934, 2),\n",
       "  (991, 1),\n",
       "  (992, 1),\n",
       "  (1020, 1),\n",
       "  (1061, 2),\n",
       "  (1142, 1),\n",
       "  (1144, 1),\n",
       "  (1168, 1),\n",
       "  (1171, 1),\n",
       "  (1199, 1),\n",
       "  (1239, 1),\n",
       "  (1255, 1),\n",
       "  (1287, 1),\n",
       "  (1309, 1),\n",
       "  (1315, 1),\n",
       "  (1354, 1),\n",
       "  (1390, 1),\n",
       "  (1422, 1),\n",
       "  (1431, 1),\n",
       "  (1435, 1),\n",
       "  (1490, 1),\n",
       "  (1512, 1),\n",
       "  (1652, 1),\n",
       "  (1690, 2),\n",
       "  (1702, 1),\n",
       "  (1713, 3),\n",
       "  (1714, 4),\n",
       "  (1733, 1),\n",
       "  (1743, 1),\n",
       "  (1765, 1),\n",
       "  (1770, 1),\n",
       "  (1776, 1),\n",
       "  (1778, 1),\n",
       "  (1779, 1)],\n",
       " [(0, 3),\n",
       "  (13, 1),\n",
       "  (21, 2),\n",
       "  (30, 2),\n",
       "  (34, 2),\n",
       "  (45, 1),\n",
       "  (51, 1),\n",
       "  (61, 1),\n",
       "  (84, 1),\n",
       "  (92, 3),\n",
       "  (100, 1),\n",
       "  (114, 1),\n",
       "  (117, 1),\n",
       "  (141, 1),\n",
       "  (153, 5),\n",
       "  (166, 1),\n",
       "  (173, 1),\n",
       "  (223, 1),\n",
       "  (237, 1),\n",
       "  (240, 1),\n",
       "  (259, 1),\n",
       "  (283, 1),\n",
       "  (284, 1),\n",
       "  (287, 1),\n",
       "  (304, 1),\n",
       "  (309, 1),\n",
       "  (311, 3),\n",
       "  (315, 1),\n",
       "  (320, 1),\n",
       "  (329, 1),\n",
       "  (371, 1),\n",
       "  (386, 1),\n",
       "  (401, 1),\n",
       "  (403, 1),\n",
       "  (416, 2),\n",
       "  (427, 1),\n",
       "  (437, 2),\n",
       "  (442, 1),\n",
       "  (472, 1),\n",
       "  (475, 1),\n",
       "  (490, 2),\n",
       "  (520, 1),\n",
       "  (533, 1),\n",
       "  (534, 1),\n",
       "  (585, 1),\n",
       "  (588, 1),\n",
       "  (589, 1),\n",
       "  (594, 3),\n",
       "  (609, 1),\n",
       "  (618, 1),\n",
       "  (619, 1),\n",
       "  (639, 1),\n",
       "  (642, 1),\n",
       "  (660, 1),\n",
       "  (665, 1),\n",
       "  (667, 1),\n",
       "  (677, 2),\n",
       "  (680, 2),\n",
       "  (706, 1),\n",
       "  (712, 5),\n",
       "  (713, 3),\n",
       "  (728, 3),\n",
       "  (731, 1),\n",
       "  (732, 1),\n",
       "  (736, 1),\n",
       "  (744, 1),\n",
       "  (767, 1),\n",
       "  (771, 1),\n",
       "  (778, 3),\n",
       "  (792, 3),\n",
       "  (799, 1),\n",
       "  (812, 1),\n",
       "  (813, 1),\n",
       "  (814, 1),\n",
       "  (817, 1),\n",
       "  (820, 1),\n",
       "  (823, 1),\n",
       "  (851, 2),\n",
       "  (866, 1),\n",
       "  (867, 1),\n",
       "  (870, 1),\n",
       "  (900, 1),\n",
       "  (906, 1),\n",
       "  (929, 1),\n",
       "  (931, 2),\n",
       "  (934, 1),\n",
       "  (950, 1),\n",
       "  (952, 1),\n",
       "  (956, 1),\n",
       "  (981, 3),\n",
       "  (986, 1),\n",
       "  (991, 1),\n",
       "  (998, 2),\n",
       "  (1016, 1),\n",
       "  (1017, 4),\n",
       "  (1024, 2),\n",
       "  (1064, 1),\n",
       "  (1084, 1),\n",
       "  (1087, 1),\n",
       "  (1093, 1),\n",
       "  (1113, 2),\n",
       "  (1126, 1),\n",
       "  (1128, 2),\n",
       "  (1130, 1),\n",
       "  (1154, 1),\n",
       "  (1168, 2),\n",
       "  (1172, 1),\n",
       "  (1174, 1),\n",
       "  (1177, 1),\n",
       "  (1183, 1),\n",
       "  (1192, 1),\n",
       "  (1207, 1),\n",
       "  (1236, 1),\n",
       "  (1237, 7),\n",
       "  (1239, 3),\n",
       "  (1265, 1),\n",
       "  (1267, 1),\n",
       "  (1269, 1),\n",
       "  (1287, 1),\n",
       "  (1295, 1),\n",
       "  (1296, 1),\n",
       "  (1308, 1),\n",
       "  (1313, 1),\n",
       "  (1330, 1),\n",
       "  (1341, 1),\n",
       "  (1443, 1),\n",
       "  (1455, 1),\n",
       "  (1478, 1),\n",
       "  (1482, 1),\n",
       "  (1483, 2),\n",
       "  (1487, 1),\n",
       "  (1494, 1),\n",
       "  (1514, 2),\n",
       "  (1539, 1),\n",
       "  (1560, 2),\n",
       "  (1561, 2),\n",
       "  (1562, 1),\n",
       "  (1569, 1),\n",
       "  (1577, 1),\n",
       "  (1578, 3),\n",
       "  (1642, 1),\n",
       "  (1645, 1),\n",
       "  (1660, 4),\n",
       "  (1661, 4),\n",
       "  (1683, 1),\n",
       "  (1690, 2),\n",
       "  (1727, 1),\n",
       "  (1736, 1),\n",
       "  (1741, 1),\n",
       "  (1754, 1),\n",
       "  (1755, 1),\n",
       "  (1764, 2),\n",
       "  (1770, 2),\n",
       "  (1771, 1),\n",
       "  (1777, 1),\n",
       "  (1791, 1),\n",
       "  (1800, 1),\n",
       "  (1806, 1),\n",
       "  (1817, 1),\n",
       "  (1819, 1),\n",
       "  (1837, 3),\n",
       "  (1848, 1),\n",
       "  (1858, 1),\n",
       "  (1859, 1)],\n",
       " [(1, 1),\n",
       "  (15, 1),\n",
       "  (30, 1),\n",
       "  (34, 2),\n",
       "  (42, 1),\n",
       "  (48, 1),\n",
       "  (51, 1),\n",
       "  (63, 1),\n",
       "  (92, 2),\n",
       "  (100, 2),\n",
       "  (114, 4),\n",
       "  (116, 2),\n",
       "  (168, 1),\n",
       "  (169, 2),\n",
       "  (194, 1),\n",
       "  (198, 2),\n",
       "  (212, 3),\n",
       "  (213, 1),\n",
       "  (216, 1),\n",
       "  (252, 1),\n",
       "  (257, 1),\n",
       "  (298, 1),\n",
       "  (299, 1),\n",
       "  (307, 1),\n",
       "  (310, 3),\n",
       "  (320, 1),\n",
       "  (327, 1),\n",
       "  (369, 1),\n",
       "  (371, 1),\n",
       "  (372, 1),\n",
       "  (407, 1),\n",
       "  (423, 4),\n",
       "  (429, 1),\n",
       "  (431, 1),\n",
       "  (437, 2),\n",
       "  (476, 1),\n",
       "  (490, 1),\n",
       "  (516, 1),\n",
       "  (529, 1),\n",
       "  (550, 1),\n",
       "  (574, 1),\n",
       "  (575, 1),\n",
       "  (592, 1),\n",
       "  (595, 1),\n",
       "  (602, 4),\n",
       "  (603, 1),\n",
       "  (609, 2),\n",
       "  (635, 1),\n",
       "  (648, 1),\n",
       "  (649, 3),\n",
       "  (652, 1),\n",
       "  (660, 2),\n",
       "  (662, 1),\n",
       "  (665, 2),\n",
       "  (683, 1),\n",
       "  (689, 1),\n",
       "  (704, 2),\n",
       "  (708, 2),\n",
       "  (718, 1),\n",
       "  (721, 1),\n",
       "  (733, 1),\n",
       "  (735, 2),\n",
       "  (739, 1),\n",
       "  (741, 2),\n",
       "  (750, 1),\n",
       "  (754, 1),\n",
       "  (768, 1),\n",
       "  (774, 1),\n",
       "  (798, 1),\n",
       "  (810, 1),\n",
       "  (812, 1),\n",
       "  (840, 1),\n",
       "  (843, 1),\n",
       "  (851, 1),\n",
       "  (852, 1),\n",
       "  (868, 1),\n",
       "  (873, 1),\n",
       "  (886, 1),\n",
       "  (892, 1),\n",
       "  (896, 1),\n",
       "  (897, 1),\n",
       "  (898, 1),\n",
       "  (899, 2),\n",
       "  (900, 3),\n",
       "  (906, 1),\n",
       "  (912, 1),\n",
       "  (941, 1),\n",
       "  (952, 2),\n",
       "  (953, 2),\n",
       "  (956, 1),\n",
       "  (965, 1),\n",
       "  (967, 1),\n",
       "  (973, 1),\n",
       "  (979, 1),\n",
       "  (985, 1),\n",
       "  (996, 2),\n",
       "  (1006, 1),\n",
       "  (1024, 1),\n",
       "  (1041, 1),\n",
       "  (1053, 1),\n",
       "  (1056, 1),\n",
       "  (1064, 3),\n",
       "  (1081, 3),\n",
       "  (1082, 3),\n",
       "  (1083, 1),\n",
       "  (1102, 1),\n",
       "  (1113, 5),\n",
       "  (1114, 2),\n",
       "  (1152, 1),\n",
       "  (1158, 1),\n",
       "  (1162, 4),\n",
       "  (1168, 3),\n",
       "  (1177, 1),\n",
       "  (1208, 1),\n",
       "  (1228, 2),\n",
       "  (1239, 1),\n",
       "  (1248, 1),\n",
       "  (1256, 1),\n",
       "  (1259, 1),\n",
       "  (1265, 1),\n",
       "  (1271, 1),\n",
       "  (1279, 1),\n",
       "  (1288, 1),\n",
       "  (1296, 1),\n",
       "  (1298, 1),\n",
       "  (1317, 1),\n",
       "  (1331, 1),\n",
       "  (1335, 1),\n",
       "  (1336, 2),\n",
       "  (1349, 1),\n",
       "  (1351, 1),\n",
       "  (1353, 1),\n",
       "  (1397, 1),\n",
       "  (1404, 1),\n",
       "  (1418, 1),\n",
       "  (1454, 1),\n",
       "  (1467, 1),\n",
       "  (1510, 1),\n",
       "  (1519, 1),\n",
       "  (1521, 2),\n",
       "  (1528, 1),\n",
       "  (1531, 3),\n",
       "  (1536, 2),\n",
       "  (1537, 1),\n",
       "  (1547, 1),\n",
       "  (1556, 1),\n",
       "  (1560, 2),\n",
       "  (1587, 1),\n",
       "  (1588, 1),\n",
       "  (1600, 1),\n",
       "  (1603, 1),\n",
       "  (1630, 2),\n",
       "  (1634, 1),\n",
       "  (1671, 1),\n",
       "  (1680, 1),\n",
       "  (1685, 1),\n",
       "  (1687, 1),\n",
       "  (1690, 2),\n",
       "  (1694, 1),\n",
       "  (1727, 1),\n",
       "  (1733, 1),\n",
       "  (1735, 1),\n",
       "  (1764, 1),\n",
       "  (1765, 1),\n",
       "  (1768, 1),\n",
       "  (1769, 1),\n",
       "  (1777, 1),\n",
       "  (1788, 3),\n",
       "  (1789, 1),\n",
       "  (1828, 1),\n",
       "  (1848, 1),\n",
       "  (1854, 1),\n",
       "  (1865, 1),\n",
       "  (1869, 1)],\n",
       " [(0, 2),\n",
       "  (1, 1),\n",
       "  (17, 1),\n",
       "  (21, 2),\n",
       "  (22, 2),\n",
       "  (23, 1),\n",
       "  (34, 5),\n",
       "  (36, 1),\n",
       "  (40, 1),\n",
       "  (42, 1),\n",
       "  (47, 1),\n",
       "  (48, 1),\n",
       "  (57, 1),\n",
       "  (62, 2),\n",
       "  (63, 1),\n",
       "  (65, 1),\n",
       "  (75, 1),\n",
       "  (79, 3),\n",
       "  (93, 1),\n",
       "  (100, 2),\n",
       "  (107, 1),\n",
       "  (111, 1),\n",
       "  (125, 2),\n",
       "  (134, 1),\n",
       "  (138, 2),\n",
       "  (142, 1),\n",
       "  (146, 1),\n",
       "  (149, 1),\n",
       "  (163, 1),\n",
       "  (174, 1),\n",
       "  (175, 1),\n",
       "  (187, 1),\n",
       "  (189, 1),\n",
       "  (230, 1),\n",
       "  (241, 1),\n",
       "  (248, 1),\n",
       "  (255, 1),\n",
       "  (260, 1),\n",
       "  (266, 1),\n",
       "  (277, 1),\n",
       "  (304, 6),\n",
       "  (311, 1),\n",
       "  (320, 2),\n",
       "  (338, 1),\n",
       "  (353, 1),\n",
       "  (368, 1),\n",
       "  (370, 1),\n",
       "  (373, 1),\n",
       "  (374, 2),\n",
       "  (375, 2),\n",
       "  (411, 1),\n",
       "  (426, 1),\n",
       "  (436, 1),\n",
       "  (437, 10),\n",
       "  (451, 1),\n",
       "  (455, 1),\n",
       "  (462, 4),\n",
       "  (473, 1),\n",
       "  (476, 1),\n",
       "  (507, 1),\n",
       "  (512, 1),\n",
       "  (513, 1),\n",
       "  (518, 1),\n",
       "  (522, 1),\n",
       "  (525, 1),\n",
       "  (537, 1),\n",
       "  (540, 1),\n",
       "  (547, 1),\n",
       "  (575, 2),\n",
       "  (581, 1),\n",
       "  (593, 2),\n",
       "  (596, 1),\n",
       "  (604, 1),\n",
       "  (606, 1),\n",
       "  (610, 1),\n",
       "  (634, 1),\n",
       "  (652, 1),\n",
       "  (660, 1),\n",
       "  (665, 1),\n",
       "  (674, 1),\n",
       "  (675, 1),\n",
       "  (678, 1),\n",
       "  (683, 1),\n",
       "  (701, 1),\n",
       "  (710, 1),\n",
       "  (718, 1),\n",
       "  (720, 1),\n",
       "  (735, 7),\n",
       "  (736, 1),\n",
       "  (746, 2),\n",
       "  (766, 1),\n",
       "  (793, 1),\n",
       "  (812, 2),\n",
       "  (818, 1),\n",
       "  (819, 1),\n",
       "  (822, 3),\n",
       "  (823, 2),\n",
       "  (837, 2),\n",
       "  (838, 1),\n",
       "  (843, 4),\n",
       "  (870, 1),\n",
       "  (894, 1),\n",
       "  (896, 1),\n",
       "  (907, 1),\n",
       "  (932, 1),\n",
       "  (938, 1),\n",
       "  (968, 1),\n",
       "  (976, 1),\n",
       "  (984, 2),\n",
       "  (992, 1),\n",
       "  (995, 1),\n",
       "  (1003, 2),\n",
       "  (1019, 2),\n",
       "  (1024, 4),\n",
       "  (1034, 3),\n",
       "  (1040, 2),\n",
       "  (1049, 1),\n",
       "  (1071, 1),\n",
       "  (1093, 4),\n",
       "  (1102, 1),\n",
       "  (1113, 1),\n",
       "  (1121, 3),\n",
       "  (1126, 1),\n",
       "  (1131, 2),\n",
       "  (1144, 1),\n",
       "  (1148, 1),\n",
       "  (1150, 2),\n",
       "  (1158, 2),\n",
       "  (1164, 1),\n",
       "  (1173, 1),\n",
       "  (1177, 1),\n",
       "  (1192, 2),\n",
       "  (1193, 1),\n",
       "  (1194, 3),\n",
       "  (1204, 3),\n",
       "  (1216, 2),\n",
       "  (1218, 3),\n",
       "  (1222, 1),\n",
       "  (1228, 1),\n",
       "  (1239, 1),\n",
       "  (1245, 1),\n",
       "  (1253, 1),\n",
       "  (1272, 1),\n",
       "  (1273, 3),\n",
       "  (1292, 1),\n",
       "  (1297, 1),\n",
       "  (1306, 1),\n",
       "  (1307, 1),\n",
       "  (1317, 2),\n",
       "  (1319, 2),\n",
       "  (1320, 2),\n",
       "  (1321, 2),\n",
       "  (1327, 1),\n",
       "  (1336, 2),\n",
       "  (1377, 2),\n",
       "  (1381, 1),\n",
       "  (1385, 1),\n",
       "  (1397, 1),\n",
       "  (1403, 2),\n",
       "  (1407, 1),\n",
       "  (1409, 1),\n",
       "  (1411, 1),\n",
       "  (1414, 1),\n",
       "  (1416, 1),\n",
       "  (1423, 2),\n",
       "  (1432, 4),\n",
       "  (1435, 1),\n",
       "  (1436, 1),\n",
       "  (1437, 1),\n",
       "  (1438, 1),\n",
       "  (1443, 3),\n",
       "  (1444, 3),\n",
       "  (1469, 1),\n",
       "  (1472, 1),\n",
       "  (1485, 1),\n",
       "  (1491, 1),\n",
       "  (1493, 3),\n",
       "  (1494, 1),\n",
       "  (1514, 1),\n",
       "  (1519, 2),\n",
       "  (1549, 1),\n",
       "  (1560, 1),\n",
       "  (1561, 1),\n",
       "  (1562, 2),\n",
       "  (1570, 1),\n",
       "  (1582, 5),\n",
       "  (1588, 15),\n",
       "  (1592, 2),\n",
       "  (1594, 3),\n",
       "  (1598, 1),\n",
       "  (1622, 4),\n",
       "  (1634, 1),\n",
       "  (1660, 1),\n",
       "  (1665, 1),\n",
       "  (1671, 3),\n",
       "  (1690, 4),\n",
       "  (1699, 1),\n",
       "  (1712, 3),\n",
       "  (1722, 1),\n",
       "  (1723, 1),\n",
       "  (1746, 1),\n",
       "  (1747, 3),\n",
       "  (1749, 3),\n",
       "  (1755, 1),\n",
       "  (1762, 1),\n",
       "  (1764, 4),\n",
       "  (1765, 1),\n",
       "  (1767, 9),\n",
       "  (1768, 1),\n",
       "  (1769, 1),\n",
       "  (1770, 1),\n",
       "  (1779, 2),\n",
       "  (1792, 1),\n",
       "  (1794, 1),\n",
       "  (1814, 3),\n",
       "  (1816, 2),\n",
       "  (1825, 1),\n",
       "  (1833, 3),\n",
       "  (1843, 1),\n",
       "  (1844, 2),\n",
       "  (1851, 4),\n",
       "  (1852, 1),\n",
       "  (1859, 1)],\n",
       " [(14, 1),\n",
       "  (17, 1),\n",
       "  (23, 1),\n",
       "  (29, 1),\n",
       "  (48, 1),\n",
       "  (56, 1),\n",
       "  (92, 1),\n",
       "  (114, 2),\n",
       "  (187, 1),\n",
       "  (250, 1),\n",
       "  (294, 1),\n",
       "  (299, 1),\n",
       "  (338, 1),\n",
       "  (369, 1),\n",
       "  (373, 1),\n",
       "  (374, 1),\n",
       "  (375, 1),\n",
       "  (389, 1),\n",
       "  (392, 1),\n",
       "  (428, 5),\n",
       "  (430, 2),\n",
       "  (491, 1),\n",
       "  (492, 1),\n",
       "  (507, 1),\n",
       "  (547, 1),\n",
       "  (571, 1),\n",
       "  (574, 1),\n",
       "  (580, 1),\n",
       "  (595, 1),\n",
       "  (607, 4),\n",
       "  (608, 1),\n",
       "  (649, 1),\n",
       "  (654, 1),\n",
       "  (659, 1),\n",
       "  (660, 1),\n",
       "  (665, 2),\n",
       "  (673, 1),\n",
       "  (706, 1),\n",
       "  (716, 1),\n",
       "  (728, 1),\n",
       "  (760, 1),\n",
       "  (771, 1),\n",
       "  (775, 1),\n",
       "  (821, 1),\n",
       "  (851, 1),\n",
       "  (852, 1),\n",
       "  (867, 1),\n",
       "  (884, 2),\n",
       "  (908, 1),\n",
       "  (952, 2),\n",
       "  (988, 1),\n",
       "  (992, 1),\n",
       "  (1000, 1),\n",
       "  (1013, 2),\n",
       "  (1024, 1),\n",
       "  (1038, 1),\n",
       "  (1058, 2),\n",
       "  (1061, 1),\n",
       "  (1062, 2),\n",
       "  (1064, 1),\n",
       "  (1103, 1),\n",
       "  (1144, 1),\n",
       "  (1158, 2),\n",
       "  (1216, 1),\n",
       "  (1228, 1),\n",
       "  (1279, 1),\n",
       "  (1281, 1),\n",
       "  (1308, 1),\n",
       "  (1319, 2),\n",
       "  (1370, 2),\n",
       "  (1371, 1),\n",
       "  (1397, 1),\n",
       "  (1408, 1),\n",
       "  (1445, 1),\n",
       "  (1455, 1),\n",
       "  (1472, 1),\n",
       "  (1481, 1),\n",
       "  (1494, 1),\n",
       "  (1502, 1),\n",
       "  (1519, 1),\n",
       "  (1524, 1),\n",
       "  (1559, 1),\n",
       "  (1560, 1),\n",
       "  (1619, 1),\n",
       "  (1652, 1),\n",
       "  (1663, 1),\n",
       "  (1676, 1),\n",
       "  (1689, 1),\n",
       "  (1690, 3),\n",
       "  (1692, 1),\n",
       "  (1696, 1),\n",
       "  (1707, 2),\n",
       "  (1713, 2),\n",
       "  (1714, 2),\n",
       "  (1755, 1),\n",
       "  (1782, 1),\n",
       "  (1790, 1),\n",
       "  (1802, 2),\n",
       "  (1811, 1),\n",
       "  (1822, 1),\n",
       "  (1825, 2),\n",
       "  (1844, 2)]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = gensim.matutils.Sparse2Corpus(descriptions_data_vectorized, documents_columns=False)\n",
    "[item for item in corpus][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{439: 'datasets',\n",
       " 372: 'contains',\n",
       " 1714: 'transactions',\n",
       " 992: 'made',\n",
       " 422: 'credit',\n",
       " 237: 'cards',\n",
       " 1512: 'september',\n",
       " 18: '2013',\n",
       " 589: 'european',\n",
       " 1144: 'occurred',\n",
       " 1733: 'two',\n",
       " 443: 'days',\n",
       " 774: 'highly',\n",
       " 1255: 'positive',\n",
       " 283: 'class',\n",
       " 39: 'account',\n",
       " 847: 'input',\n",
       " 1779: 'variables',\n",
       " 1435: 'result',\n",
       " 1743: 'unfortunately',\n",
       " 528: 'due',\n",
       " 881: 'issues',\n",
       " 230: 'cannot',\n",
       " 1315: 'provide',\n",
       " 1168: 'original',\n",
       " 642: 'features',\n",
       " 168: 'background',\n",
       " 843: 'information',\n",
       " 343: 'components',\n",
       " 1142: 'obtained',\n",
       " 1690: 'time',\n",
       " 98: 'amount',\n",
       " 641: 'feature',\n",
       " 1490: 'seconds',\n",
       " 1713: 'transaction',\n",
       " 665: 'first',\n",
       " 1765: 'used',\n",
       " 602: 'example',\n",
       " 399: 'cost',\n",
       " 934: 'learning',\n",
       " 1431: 'response',\n",
       " 1778: 'variable',\n",
       " 1652: 'takes',\n",
       " 1776: 'value',\n",
       " 240: 'case',\n",
       " 1171: 'otherwise',\n",
       " 733: 'given',\n",
       " 1354: 'ratio',\n",
       " 41: 'accuracy',\n",
       " 1770: 'using',\n",
       " 132: 'area',\n",
       " 1020: 'matrix',\n",
       " 285: 'classification',\n",
       " 302: 'collected',\n",
       " 1422: 'research',\n",
       " 991: 'machine',\n",
       " 753: 'group',\n",
       " 792: 'http',\n",
       " 191: 'big',\n",
       " 1061: 'mining',\n",
       " 478: 'detection',\n",
       " 476: 'details',\n",
       " 431: 'current',\n",
       " 1199: 'past',\n",
       " 1309: 'projects',\n",
       " 1390: 'related',\n",
       " 1702: 'topics',\n",
       " 163: 'available',\n",
       " 1239: 'please',\n",
       " 276: 'cite',\n",
       " 1287: 'probability',\n",
       " 347: 'computational',\n",
       " 861: 'intelligence',\n",
       " 806: 'ieee',\n",
       " 20: '2015',\n",
       " 437: 'database',\n",
       " 100: 'analysis',\n",
       " 728: 'get',\n",
       " 0: '000',\n",
       " 1017: 'matches',\n",
       " 1237: 'players',\n",
       " 403: 'countries',\n",
       " 929: 'lead',\n",
       " 1487: 'seasons',\n",
       " 13: '2008',\n",
       " 21: '2016',\n",
       " 1661: 'teams',\n",
       " 153: 'attributes',\n",
       " 1561: 'sourced',\n",
       " 1578: 'sports',\n",
       " 1791: 'video',\n",
       " 712: 'game',\n",
       " 1514: 'series',\n",
       " 823: 'including',\n",
       " 1819: 'weekly',\n",
       " 1755: 'updates',\n",
       " 1660: 'team',\n",
       " 956: 'line',\n",
       " 386: 'coordinates',\n",
       " 475: 'detailed',\n",
       " 1016: 'match',\n",
       " 594: 'events',\n",
       " 736: 'goal',\n",
       " 1736: 'types',\n",
       " 427: 'cross',\n",
       " 588: 'etc',\n",
       " 1113: 'new',\n",
       " 1645: 'table',\n",
       " 371: 'containing',\n",
       " 1560: 'source',\n",
       " 534: 'easily',\n",
       " 660: 'find',\n",
       " 1771: 'usually',\n",
       " 51: 'across',\n",
       " 490: 'different',\n",
       " 1817: 'websites',\n",
       " 304: 'collection',\n",
       " 1295: 'processing',\n",
       " 520: 'done',\n",
       " 998: 'make',\n",
       " 950: 'life',\n",
       " 533: 'easier',\n",
       " 1087: 'must',\n",
       " 320: 'commercial',\n",
       " 1764: 'use',\n",
       " 677: 'football',\n",
       " 114: 'api',\n",
       " 311: 'com',\n",
       " 1478: 'scores',\n",
       " 1859: 'www',\n",
       " 1741: 'understand',\n",
       " 309: 'column',\n",
       " 1642: 'system',\n",
       " 713: 'games',\n",
       " 1313: 'property',\n",
       " 981: 'look',\n",
       " 1128: 'notice',\n",
       " 680: 'foreign',\n",
       " 1562: 'sources',\n",
       " 223: 'called',\n",
       " 817: 'improving',\n",
       " 1064: 'missing',\n",
       " 1130: 'null',\n",
       " 1777: 'values',\n",
       " 30: 'able',\n",
       " 667: 'fixed',\n",
       " 416: 'crawling',\n",
       " 84: 'algorithm',\n",
       " 814: 'improved',\n",
       " 92: 'also',\n",
       " 820: 'include',\n",
       " 870: 'international',\n",
       " 1093: 'national',\n",
       " 931: 'league',\n",
       " 141: 'ask',\n",
       " 1569: 'specific',\n",
       " 1806: 'want',\n",
       " 767: 'help',\n",
       " 813: 'improve',\n",
       " 34: 'access',\n",
       " 1308: 'project',\n",
       " 731: 'github',\n",
       " 812: 'important',\n",
       " 1126: 'note',\n",
       " 1207: 'people',\n",
       " 866: 'interested',\n",
       " 1539: 'since',\n",
       " 1858: 'wrote',\n",
       " 1483: 'scripts',\n",
       " 1330: 'python',\n",
       " 117: 'appears',\n",
       " 259: 'changed',\n",
       " 472: 'design',\n",
       " 315: 'comes',\n",
       " 609: 'existing',\n",
       " 1482: 'script',\n",
       " 1236: 'player',\n",
       " 1848: 'work',\n",
       " 1754: 'updated',\n",
       " 619: 'exploring',\n",
       " 706: 'fun',\n",
       " 1192: 'part',\n",
       " 986: 'lot',\n",
       " 61: 'adding',\n",
       " 851: 'insights',\n",
       " 1177: 'overview',\n",
       " 1183: 'page',\n",
       " 900: 'kernels',\n",
       " 732: 'give',\n",
       " 1727: 'try',\n",
       " 799: 'ideas',\n",
       " 1265: 'predict',\n",
       " 1172: 'outcome',\n",
       " 284: 'classes',\n",
       " 778: 'home',\n",
       " 1837: 'win',\n",
       " 166: 'away',\n",
       " 1443: 'right',\n",
       " 45: 'achieved',\n",
       " 639: 'far',\n",
       " 1683: 'though',\n",
       " 1024: 'may',\n",
       " 771: 'high',\n",
       " 1341: 'random',\n",
       " 1577: 'sport',\n",
       " 744: 'got',\n",
       " 906: 'know',\n",
       " 173: 'base',\n",
       " 1267: 'predicting',\n",
       " 1455: 'running',\n",
       " 1084: 'multi',\n",
       " 287: 'classifier',\n",
       " 952: 'like',\n",
       " 401: 'could',\n",
       " 1174: 'output',\n",
       " 585: 'estimate',\n",
       " 329: 'compare',\n",
       " 1494: 'see',\n",
       " 1269: 'predictions',\n",
       " 618: 'explore',\n",
       " 1800: 'visualize',\n",
       " 1296: 'produce',\n",
       " 867: 'interesting',\n",
       " 1154: 'one',\n",
       " 442: 'day',\n",
       " 1467: 'say',\n",
       " 1630: 'success',\n",
       " 1081: 'movie',\n",
       " 1397: 'released',\n",
       " 252: 'certain',\n",
       " 327: 'companies',\n",
       " 689: 'found',\n",
       " 996: 'major',\n",
       " 1: '100',\n",
       " 1056: 'million',\n",
       " 1603: 'still',\n",
       " 1335: 'question',\n",
       " 595: 'ever',\n",
       " 840: 'industry',\n",
       " 1053: 'might',\n",
       " 868: 'interests',\n",
       " 1349: 'rated',\n",
       " 1828: 'whether',\n",
       " 750: 'great',\n",
       " 1228: 'place',\n",
       " 1588: 'start',\n",
       " 1336: 'questions',\n",
       " 212: 'budget',\n",
       " 1521: 'several',\n",
       " 1685: 'thousand',\n",
       " 1634: 'summary',\n",
       " 896: 'kaggle',\n",
       " 1404: 'removed',\n",
       " 1788: 'version',\n",
       " 1208: 'per',\n",
       " 1418: 'request',\n",
       " 1162: 'order',\n",
       " 810: 'impact',\n",
       " 1536: 'similar',\n",
       " 1519: 'set',\n",
       " 649: 'fields',\n",
       " 1671: 'terms',\n",
       " 169: 'bad',\n",
       " 1114: 'news',\n",
       " 216: 'built',\n",
       " 1152: 'old',\n",
       " 953: 'likely',\n",
       " 979: 'longer',\n",
       " 741: 'good',\n",
       " 198: 'bit',\n",
       " 899: 'kernel',\n",
       " 708: 'functions',\n",
       " 603: 'examples',\n",
       " 718: 'general',\n",
       " 873: 'introduction',\n",
       " 683: 'format',\n",
       " 704: 'full',\n",
       " 423: 'credits',\n",
       " 1351: 'rather',\n",
       " 1687: 'three',\n",
       " 965: 'listed',\n",
       " 116: 'appear',\n",
       " 1082: 'movies',\n",
       " 550: 'either',\n",
       " 15: '2010',\n",
       " 735: 'global',\n",
       " 194: 'billion',\n",
       " 407: 'couple',\n",
       " 574: 'entries',\n",
       " 575: 'entry',\n",
       " 42: 'accurate',\n",
       " 967: 'lists',\n",
       " 1587: 'star',\n",
       " 310: 'columns',\n",
       " 369: 'contain',\n",
       " 892: 'json',\n",
       " 973: 'load',\n",
       " 592: 'even',\n",
       " 1537: 'simple',\n",
       " 1789: 'versions',\n",
       " 1279: 'previous',\n",
       " 1531: 'shows',\n",
       " 529: 'duration',\n",
       " 1510: 'separate',\n",
       " 652: 'file',\n",
       " 1768: 'users',\n",
       " 1353: 'ratings',\n",
       " 1454: 'run',\n",
       " 429: 'curious',\n",
       " 1271: 'prepared',\n",
       " 299: 'code',\n",
       " 1259: 'posted',\n",
       " 1248: 'popularity',\n",
       " 1600: 'status',\n",
       " 985: 'lost',\n",
       " 307: 'color',\n",
       " 1158: 'open',\n",
       " 1680: 'things',\n",
       " 257: 'chance',\n",
       " 941: 'let',\n",
       " 516: 'dollars',\n",
       " 1528: 'show',\n",
       " 1865: 'yet',\n",
       " 1331: 'quality',\n",
       " 1102: 'necessary',\n",
       " 1869: 'zero',\n",
       " 648: 'field',\n",
       " 662: 'findings',\n",
       " 1854: 'would',\n",
       " 768: 'helpful',\n",
       " 897: 'kagglers',\n",
       " 1288: 'probably',\n",
       " 798: 'idea',\n",
       " 898: 'keep',\n",
       " 1083: 'much',\n",
       " 1547: 'small',\n",
       " 852: 'inspiration',\n",
       " 1735: 'type',\n",
       " 912: 'labels',\n",
       " 1256: 'possible',\n",
       " 213: 'build',\n",
       " 886: 'job',\n",
       " 1694: 'titles',\n",
       " 754: 'groups',\n",
       " 635: 'fall',\n",
       " 298: 'clustering',\n",
       " 1556: 'something',\n",
       " 739: 'going',\n",
       " 48: 'acknowledgements',\n",
       " 721: 'generated',\n",
       " 1298: 'product',\n",
       " 1769: 'uses',\n",
       " 1317: 'provides',\n",
       " 1006: 'many',\n",
       " 63: 'additional',\n",
       " 1041: 'members',\n",
       " 375: 'context',\n",
       " 134: 'around',\n",
       " 1851: 'world',\n",
       " 107: 'annual',\n",
       " 710: 'future',\n",
       " 822: 'includes',\n",
       " 518: 'domestic',\n",
       " 1825: 'well',\n",
       " 819: 'incidents',\n",
       " 1216: 'period',\n",
       " 241: 'cases',\n",
       " 995: 'maintained',\n",
       " 1423: 'researchers',\n",
       " 1622: 'study',\n",
       " 1432: 'responses',\n",
       " 1749: 'university',\n",
       " 373: 'content',\n",
       " 1852: 'worldwide',\n",
       " 606: 'except',\n",
       " 22: '2017',\n",
       " 1307: 'progress',\n",
       " 1320: 'publication',\n",
       " 610: 'expected',\n",
       " 894: 'june',\n",
       " 23: '2018',\n",
       " 1746: 'unit',\n",
       " 149: 'attack',\n",
       " 976: 'location',\n",
       " 1173: 'outcomes',\n",
       " 1034: 'media',\n",
       " 138: 'articles',\n",
       " 260: 'changes',\n",
       " 1204: 'patterns',\n",
       " 525: 'driven',\n",
       " 1722: 'trends',\n",
       " 1194: 'particular',\n",
       " 1385: 'regions',\n",
       " 411: 'coverage',\n",
       " 455: 'definition',\n",
       " 57: 'actual',\n",
       " 678: 'force',\n",
       " 1121: 'non',\n",
       " 1592: 'state',\n",
       " 1245: 'political',\n",
       " 537: 'economic',\n",
       " 1549: 'social',\n",
       " 1049: 'methodology',\n",
       " 1469: 'schema',\n",
       " 462: 'department',\n",
       " 1131: 'number',\n",
       " 1493: 'security',\n",
       " 1472: 'science',\n",
       " 1665: 'technology',\n",
       " 1148: 'office',\n",
       " 1306: 'programs',\n",
       " 17: '2012',\n",
       " 451: 'decisions',\n",
       " 370: 'contained',\n",
       " 1416: 'representing',\n",
       " 1150: 'official',\n",
       " 1794: 'views',\n",
       " 1747: 'united',\n",
       " 1594: 'states',\n",
       " 746: 'government',\n",
       " 1321: 'publications',\n",
       " 1409: 'reports',\n",
       " 1222: 'perspective',\n",
       " 255: 'challenges',\n",
       " 79: 'agreement',\n",
       " 674: 'following',\n",
       " 353: 'conditions',\n",
       " 1843: 'within',\n",
       " 1491: 'section',\n",
       " 1377: 'refer',\n",
       " 1297: 'produced',\n",
       " 1019: 'materials',\n",
       " 1272: 'present',\n",
       " 1833: 'wide',\n",
       " 1814: 'web',\n",
       " 1273: 'presented',\n",
       " 248: 'center',\n",
       " 174: 'based',\n",
       " 1767: 'user',\n",
       " 837: 'individual',\n",
       " 838: 'individuals',\n",
       " 1003: 'management',\n",
       " 1582: 'staff',\n",
       " 1414: 'representative',\n",
       " 1164: 'organization',\n",
       " 1411: 'represent',\n",
       " 1762: 'usage',\n",
       " 1444: 'rights',\n",
       " 1485: 'search',\n",
       " 1792: 'view',\n",
       " 374: 'contents',\n",
       " 1381: 'reflect',\n",
       " 1253: 'position',\n",
       " 75: 'agency',\n",
       " 47: 'acknowledgement',\n",
       " 277: 'cited',\n",
       " 675: 'follows',\n",
       " 1438: 'retrieved',\n",
       " 793: 'https',\n",
       " 1816: 'website',\n",
       " 36: 'accessible',\n",
       " 1319: 'public',\n",
       " 522: 'download',\n",
       " 1844: 'without',\n",
       " 1218: 'permission',\n",
       " 1040: 'member',\n",
       " 62: 'addition',\n",
       " 507: 'distributed',\n",
       " 1327: 'purpose',\n",
       " 984: 'loss',\n",
       " 125: 'appropriate',\n",
       " 938: 'legal',\n",
       " 93: 'although',\n",
       " 596: 'every',\n",
       " 547: 'effort',\n",
       " 266: 'check',\n",
       " 634: 'facts',\n",
       " 40: 'accounts',\n",
       " 1407: 'reported',\n",
       " 968: 'literature',\n",
       " 338: 'complete',\n",
       " 766: 'held',\n",
       " 436: 'damage',\n",
       " 581: 'errors',\n",
       " 1436: 'resulting',\n",
       " 1437: 'results',\n",
       " 189: 'beyond',\n",
       " 1570: 'specifically',\n",
       " 146: 'associated',\n",
       " 818: 'incident',\n",
       " 1723: 'tried',\n",
       " 426: 'criminal',\n",
       " 513: 'documentation',\n",
       " 593: 'event',\n",
       " 1071: 'modified',\n",
       " 1403: 'remove',\n",
       " 65: 'address',\n",
       " 512: 'document',\n",
       " 1712: 'training',\n",
       " 473: 'designed',\n",
       " 907: 'knowledge',\n",
       " 1699: 'tools',\n",
       " 187: 'best',\n",
       " 1292: 'process',\n",
       " 1193: 'participants',\n",
       " 932: 'learn',\n",
       " 175: 'basic',\n",
       " 720: 'generate',\n",
       " 1598: 'statistics',\n",
       " 604: 'excel',\n",
       " 111: 'answers',\n",
       " 701: 'frequently',\n",
       " 142: 'asked',\n",
       " 368: 'contact',\n",
       " 540: 'edu',\n",
       " 908: 'known',\n",
       " 14: '2009',\n",
       " 1038: 'medium',\n",
       " 492: 'digital',\n",
       " 607: 'exchange',\n",
       " 1371: 'recorded',\n",
       " 1103: 'need',\n",
       " 1370: 'record',\n",
       " 250: 'central',\n",
       " 1689: 'thus',\n",
       " 1696: 'together',\n",
       " 430: 'currency',\n",
       " 1013: 'market',\n",
       " 1707: 'trading',\n",
       " 659: 'financial',\n",
       " 1559: 'soon',\n",
       " 673: 'followed',\n",
       " 821: 'included',\n",
       " 775: 'historical',\n",
       " 1058: 'min',\n",
       " 760: 'happy',\n",
       " 428: 'csv',\n",
       " 654: 'files',\n",
       " 884: 'jan',\n",
       " 1062: 'minute',\n",
       " 988: 'low',\n",
       " 294: 'close',\n",
       " 1802: 'volume',\n",
       " 1822: 'weighted',\n",
       " 1281: 'price',\n",
       " 56: 'activity',\n",
       " 1692: 'timestamp',\n",
       " 608: 'exist',\n",
       " 1663: 'technical',\n",
       " 580: 'error',\n",
       " 1408: 'reporting',\n",
       " 716: 'gathering',\n",
       " 392: 'correct',\n",
       " 29: 'ability',\n",
       " 1445: 'risk',\n",
       " 1782: 'various',\n",
       " 1000: 'making',\n",
       " 491: 'difficult',\n",
       " 571: 'enough',\n",
       " 1481: 'scraping',\n",
       " 389: 'core',\n",
       " 1790: 'via',\n",
       " 1676: 'thank',\n",
       " 1524: 'share',\n",
       " 1619: 'student',\n",
       " 1502: 'send',\n",
       " 1811: 'way',\n",
       " 355: 'conducted',\n",
       " 1640: 'survey',\n",
       " 345: 'comprehensive',\n",
       " 1365: 'received',\n",
       " 933: 'learned',\n",
       " 1849: 'working',\n",
       " 839: 'industries',\n",
       " 1475: 'scientists',\n",
       " 845: 'initial',\n",
       " 1329: 'put',\n",
       " 864: 'interactive',\n",
       " 1406: 'report',\n",
       " 1525: 'shared',\n",
       " 396: 'correspond',\n",
       " 1088: 'name',\n",
       " 1085: 'multiple',\n",
       " 272: 'choice',\n",
       " 1345: 'ranking',\n",
       " 1540: 'single',\n",
       " 1451: 'row',\n",
       " 1358: 'reading',\n",
       " 1350: 'rates',\n",
       " 1763: 'usd',\n",
       " 35: 'accessed',\n",
       " 1182: 'package',\n",
       " 1734: 'txt',\n",
       " 1129: 'november',\n",
       " 1074: 'month',\n",
       " 2: '1000',\n",
       " 1818: 'week',\n",
       " 99: 'analyses',\n",
       " 1356: 'read',\n",
       " 903: 'kind',\n",
       " 404: 'country',\n",
       " 940: 'less',\n",
       " 1089: 'named',\n",
       " 109: 'answer',\n",
       " 1382: 'regarding',\n",
       " 557: 'employment',\n",
       " 1420: 'required',\n",
       " 833: 'indicates',\n",
       " 1283: 'primarily',\n",
       " 555: 'email',\n",
       " 964: 'list',\n",
       " 502: 'discussion',\n",
       " 970: 'live',\n",
       " 157: 'august',\n",
       " 1035: 'median',\n",
       " 1063: 'minutes',\n",
       " 87: 'allowed',\n",
       " 1458: 'salary',\n",
       " 1855: 'write',\n",
       " 1703: 'total',\n",
       " 1316: 'provided',\n",
       " 1348: 'rate',\n",
       " 219: 'calculate',\n",
       " 1530: 'shown',\n",
       " 150: 'attempt',\n",
       " 1400: 'relevant',\n",
       " 719: 'generally',\n",
       " 1620: 'students',\n",
       " 468: 'describes',\n",
       " 1644: 'tab',\n",
       " 1511: 'separated',\n",
       " 563: 'ended',\n",
       " 901: 'key',\n",
       " 695: 'free',\n",
       " 682: 'form',\n",
       " 1841: 'wise',\n",
       " 314: 'come',\n",
       " 1188: 'paper',\n",
       " 1032: 'measurements',\n",
       " 1290: 'problems',\n",
       " 1739: 'uci',\n",
       " 1410: 'repository',\n",
       " 1568: 'species',\n",
       " 1463: 'samples',\n",
       " 1312: 'properties',\n",
       " 483: 'development',\n",
       " 836: 'indicators',\n",
       " 171: 'bank',\n",
       " 796: 'hundreds',\n",
       " 90: 'along',\n",
       " 197: 'birth',\n",
       " 782: 'hosted',\n",
       " 1546: 'slightly',\n",
       " 1355: 'raw',\n",
       " 630: 'facilitate',\n",
       " 101: 'analytics',\n",
       " 58: 'actually',\n",
       " 452: 'deep',\n",
       " 1118: 'nlp',\n",
       " 408: 'course',\n",
       " 1234: 'play',\n",
       " 470: 'description',\n",
       " 415: 'crawled',\n",
       " 1375: 'reddit',\n",
       " 1805: 'votes',\n",
       " 1700: 'top',\n",
       " 361: 'considered',\n",
       " 440: 'date',\n",
       " 1343: 'range',\n",
       " 1604: 'stock',\n",
       " 164: 'average',\n",
       " 1488: 'second',\n",
       " 783: 'hot',\n",
       " 770: 'hence',\n",
       " 958: 'lines',\n",
       " 523: 'downloaded',\n",
       " 496: 'directly',\n",
       " 658: 'finance',\n",
       " 842: 'info',\n",
       " 313: 'combined',\n",
       " 909: 'label',\n",
       " 1155: 'ones',\n",
       " 195: 'binary',\n",
       " 1656: 'task',\n",
       " 591: 'evaluation',\n",
       " 19: '2014',\n",
       " 1672: 'test',\n",
       " 1863: 'years',\n",
       " 1449: 'roughly',\n",
       " 1575: 'split',\n",
       " 1268: 'prediction',\n",
       " 1681: 'think',\n",
       " 1072: 'money',\n",
       " 646: 'feel',\n",
       " 177: 'become',\n",
       " 1599: 'stats',\n",
       " 453: 'defense',\n",
       " 1567: 'special',\n",
       " 1573: 'speed',\n",
       " 467: 'described',\n",
       " 1633: 'sum',\n",
       " 756: 'guide',\n",
       " 1615: 'strong',\n",
       " 777: 'hit',\n",
       " 1242: 'points',\n",
       " 764: 'health',\n",
       " 1123: 'normal',\n",
       " 664: 'fire',\n",
       " 1450: 'round',\n",
       " 50: 'acquired',\n",
       " 1542: 'sites',\n",
       " 110: 'answered',\n",
       " 1564: 'space',\n",
       " 1026: 'mean',\n",
       " 420: 'creation',\n",
       " 1797: 'visual',\n",
       " 987: 'love',\n",
       " 880: 'issued',\n",
       " 12: '2007',\n",
       " 705: 'fully',\n",
       " 1185: 'paid',\n",
       " 925: 'latest',\n",
       " 339: 'completed',\n",
       " 1871: 'zip',\n",
       " 300: 'codes',\n",
       " 97: 'among',\n",
       " 1170: 'others',\n",
       " 1139: 'observations',\n",
       " 486: 'dictionary',\n",
       " 1015: 'master',\n",
       " 417: 'create',\n",
       " 1270: 'predictive',\n",
       " 803: 'identify',\n",
       " 1601: 'step',\n",
       " 1710: 'train',\n",
       " 1231: 'plan',\n",
       " 1781: 'variety',\n",
       " 1847: 'words',\n",
       " 1440: 'review',\n",
       " 112: 'anyone',\n",
       " 1258: 'post',\n",
       " 364: 'consists',\n",
       " 1468: 'scale',\n",
       " 1441: 'reviews',\n",
       " 1476: 'score',\n",
       " 1693: 'title',\n",
       " 1151: 'often',\n",
       " 626: 'extracting',\n",
       " 1508: 'sentences',\n",
       " 469: 'describing',\n",
       " 1383: 'region',\n",
       " 1557: 'sometimes',\n",
       " 1571: 'specified',\n",
       " 849: 'inside',\n",
       " 199: 'blank',\n",
       " 1219: 'person',\n",
       " 1732: 'twitter',\n",
       " 1480: 'scraped',\n",
       " 1753: 'update',\n",
       " 645: 'feedback',\n",
       " 1861: 'year',\n",
       " 879: 'issue',\n",
       " 1509: 'sentiment',\n",
       " 1674: 'text',\n",
       " 1069: 'models',\n",
       " 1176: 'overall',\n",
       " 293: 'climate',\n",
       " 258: 'change',\n",
       " 73: 'age',\n",
       " 1520: 'sets',\n",
       " 794: 'huge',\n",
       " 291: 'cleaning',\n",
       " 738: 'goes',\n",
       " 978: 'long',\n",
       " 531: 'early',\n",
       " 1780: 'variation',\n",
       " 1796: 'visit',\n",
       " 1813: 'weather',\n",
       " 1596: 'stations',\n",
       " 1078: 'move',\n",
       " 552: 'electronic',\n",
       " 1165: 'organizations',\n",
       " 916: 'land',\n",
       " 1667: 'temperature',\n",
       " 1091: 'nasa',\n",
       " 532: 'earth',\n",
       " 914: 'laboratory',\n",
       " 1639: 'surface',\n",
       " 1264: 'pre',\n",
       " 131: 'archives',\n",
       " 88: 'allows',\n",
       " 1323: 'publish',\n",
       " 121: 'applied',\n",
       " 1050: 'methods',\n",
       " 86: 'allow',\n",
       " 1027: 'meaning',\n",
       " 1591: 'starts',\n",
       " 1022: 'max',\n",
       " 1023: 'maximum',\n",
       " 1060: 'minimum',\n",
       " 280: 'city',\n",
       " 676: 'food',\n",
       " 1300: 'products',\n",
       " 597: 'everyone',\n",
       " 1304: 'profit',\n",
       " 147: 'association',\n",
       " 1803: 'volunteers',\n",
       " 381: 'contributors',\n",
       " 60: 'added',\n",
       " 1223: 'phone',\n",
       " 115: 'app',\n",
       " 1756: 'upload',\n",
       " 865: 'interest',\n",
       " 1324: 'published',\n",
       " 1616: 'structure',\n",
       " 1580: 'sqlite',\n",
       " 1760: 'url',\n",
       " 1332: 'quantity',\n",
       " 243: 'categories',\n",
       " 278: 'cities',\n",
       " 1133: 'numeric',\n",
       " 825: 'increase',\n",
       " 306: 'college',\n",
       " 1198: 'party',\n",
       " 1470: 'school',\n",
       " 91: 'already',\n",
       " 1590: 'starting',\n",
       " 463: 'depending',\n",
       " 826: 'increased',\n",
       " 1262: 'power',\n",
       " 1668: 'ten',\n",
       " 1471: 'schools',\n",
       " 567: 'engineering',\n",
       " 990: 'lowest',\n",
       " 38: 'according',\n",
       " 221: 'california',\n",
       " 456: 'degree',\n",
       " 1626: 'subjects',\n",
       " 1430: 'respectively',\n",
       " 755: 'growth',\n",
       " 1612: 'street',\n",
       " 890: 'journal',\n",
       " 457: 'degrees',\n",
       " 1205: 'pay',\n",
       " 167: 'back',\n",
       " 1169: 'originally',\n",
       " 378: 'contributed',\n",
       " 1101: 'nearly',\n",
       " 78: 'ago',\n",
       " 445: 'death',\n",
       " 263: 'characteristics',\n",
       " 471: 'descriptions',\n",
       " 397: 'corresponding',\n",
       " 637: 'family',\n",
       " 524: 'drawn',\n",
       " 1550: 'society',\n",
       " 1125: 'north',\n",
       " 96: 'american',\n",
       " 801: 'identified',\n",
       " 1750: 'unknown',\n",
       " 128: 'april',\n",
       " 1211: 'perform',\n",
       " 807: 'image',\n",
       " 663: 'fine',\n",
       " 1014: 'mass',\n",
       " 466: 'describe',\n",
       " 246: 'cell',\n",
       " 957: 'linear',\n",
       " 1551: 'software',\n",
       " 1516: 'server',\n",
       " 130: 'archive',\n",
       " 797: 'ics',\n",
       " 227: 'cancer',\n",
       " 152: 'attribute',\n",
       " 1360: 'real',\n",
       " 1583: 'standard',\n",
       " 974: 'local',\n",
       " 921: 'largest',\n",
       " 854: 'instance',\n",
       " 691: 'four',\n",
       " 1535: 'significant',\n",
       " 493: 'digits',\n",
       " 1122: 'none',\n",
       " 508: 'distribution',\n",
       " 27: '500',\n",
       " 1146: 'october',\n",
       " 1326: 'pulled',\n",
       " 1334: 'query',\n",
       " 1337: 'quick',\n",
       " 1461: 'sample',\n",
       " 1068: 'modeling',\n",
       " 1157: 'online',\n",
       " 1682: 'third',\n",
       " 944: 'levels',\n",
       " 1095: 'nations',\n",
       " 1010: 'march',\n",
       " 711: 'gain',\n",
       " 1368: 'recognition',\n",
       " 281: 'civil',\n",
       " 1244: 'policy',\n",
       " 930: 'leading',\n",
       " 144: 'assess',\n",
       " 1695: 'today',\n",
       " 1220: 'personal',\n",
       " 1346: 'rankings',\n",
       " 993: 'main',\n",
       " 971: 'lives',\n",
       " 1823: 'weights',\n",
       " 587: 'estimates',\n",
       " 622: 'extent',\n",
       " 1543: 'six',\n",
       " 633: 'factors',\n",
       " 1299: 'production',\n",
       " 1637: 'support',\n",
       " 696: 'freedom',\n",
       " 377: 'contribute',\n",
       " 772: 'higher',\n",
       " 578: 'equal',\n",
       " 614: 'explain',\n",
       " 1344: 'rank',\n",
       " 773: 'highest',\n",
       " 612: 'experience',\n",
       " 935: 'least',\n",
       " 184: 'benchmark',\n",
       " 330: 'compared',\n",
       " 1624: 'sub',\n",
       " 1140: 'observed',\n",
       " 1678: 'therefore',\n",
       " 487: 'differ',\n",
       " 127: 'approximately',\n",
       " 1831: 'whole',\n",
       " 651: 'figure',\n",
       " 94: 'always',\n",
       " 1496: 'seen',\n",
       " 1339: 'quite',\n",
       " 919: 'large',\n",
       " 1241: 'point',\n",
       " 1548: 'smaller',\n",
       " 220: 'calculated',\n",
       " 232: 'capita',\n",
       " 59: 'add',\n",
       " 1401: 'reliable',\n",
       " 137: 'article',\n",
       " 809: 'images',\n",
       " 363: 'consisting',\n",
       " 1515: 'serve',\n",
       " 494: 'direct',\n",
       " 85: 'algorithms',\n",
       " 1544: 'size',\n",
       " 1673: 'testing',\n",
       " 326: 'community',\n",
       " 631: 'fact',\n",
       " 1227: 'pixels',\n",
       " 765: 'height',\n",
       " 834: 'indicating',\n",
       " 1132: 'numbers',\n",
       " 860: 'integer',\n",
       " 1417: 'represents',\n",
       " 1434: 'rest',\n",
       " 975: 'located',\n",
       " 937: 'left',\n",
       " 145: 'assigned',\n",
       " 1402: 'remaining',\n",
       " 383: 'converted',\n",
       " 947: 'license',\n",
       " 1065: 'mit',\n",
       " 388: 'copyright',\n",
       " 1662: 'tech',\n",
       " 265: 'charge',\n",
       " 387: 'copy',\n",
       " 444: 'deal',\n",
       " 1221: 'persons',\n",
       " 1625: 'subject',\n",
       " 955: 'limited',\n",
       " 159: 'authors',\n",
       " 282: 'claim',\n",
       " 53: 'action',\n",
       " 359: 'connection',\n",
       " 1275: 'presidential',\n",
       " 551: 'election',\n",
       " 1284: 'primary',\n",
       " 617: 'exploration',\n",
       " 229: 'candidates',\n",
       " 394: 'correlated',\n",
       " 228: 'candidate',\n",
       " 406: 'county',\n",
       " 499: 'discover',\n",
       " 1008: 'mapping',\n",
       " 687: 'forum',\n",
       " 572: 'entire',\n",
       " 960: 'link',\n",
       " 497: 'directory',\n",
       " 943: 'level',\n",
       " 638: 'famous',\n",
       " 203: 'book',\n",
       " 1558: 'song',\n",
       " 264: 'characters',\n",
       " 700: 'frequent',\n",
       " 262: 'character',\n",
       " 446: 'deaths',\n",
       " ...}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_map = dict((v, k) for k, v in vectorizer.vocabulary_.items()) \n",
    "id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=10, id2word=id_map)#, passes=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.013*\"content\" + 0.012*\"information\" + 0.010*\"com\" + 0.010*\"tweet\" + 0.009*\"context\" + 0.009*\"many\" + 0.009*\"inspiration\" + 0.009*\"used\" + 0.008*\"acknowledgements\" + 0.007*\"times\" + 0.007*\"contains\" + 0.007*\"using\" + 0.007*\"https\" + 0.007*\"would\" + 0.007*\"like\" + 0.006*\"url\" + 0.006*\"tweets\" + 0.006*\"time\" + 0.006*\"number\" + 0.005*\"datasets\"'),\n",
       " (1,\n",
       "  '0.022*\"college\" + 0.012*\"university\" + 0.010*\"company\" + 0.009*\"name\" + 0.008*\"state\" + 0.008*\"time\" + 0.008*\"context\" + 0.007*\"2017\" + 0.007*\"one\" + 0.007*\"content\" + 0.007*\"gov\" + 0.007*\"nationality\" + 0.006*\"open\" + 0.006*\"using\" + 0.006*\"number\" + 0.006*\"day\" + 0.006*\"acknowledgements\" + 0.006*\"companies\" + 0.006*\"file\" + 0.006*\"contains\"'),\n",
       " (2,\n",
       "  '0.010*\"time\" + 0.010*\"csv\" + 0.009*\"news\" + 0.008*\"context\" + 0.008*\"investment\" + 0.008*\"content\" + 0.007*\"know\" + 0.007*\"sports\" + 0.007*\"contains\" + 0.007*\"find\" + 0.006*\"new\" + 0.006*\"total\" + 0.006*\"game\" + 0.006*\"scores\" + 0.006*\"years\" + 0.006*\"date\" + 0.006*\"share\" + 0.006*\"information\" + 0.005*\"direction\" + 0.005*\"world\"'),\n",
       " (3,\n",
       "  '0.018*\"csv\" + 0.011*\"content\" + 0.011*\"context\" + 0.009*\"https\" + 0.009*\"www\" + 0.009*\"information\" + 0.009*\"education\" + 0.009*\"file\" + 0.008*\"acknowledgements\" + 0.008*\"gov\" + 0.007*\"number\" + 0.007*\"row\" + 0.007*\"2015\" + 0.006*\"used\" + 0.006*\"inspiration\" + 0.006*\"educational\" + 0.006*\"1995\" + 0.006*\"files\" + 0.006*\"json\" + 0.006*\"http\"'),\n",
       " (4,\n",
       "  '0.044*\"description\" + 0.044*\"yet\" + 0.012*\"csv\" + 0.011*\"city\" + 0.011*\"number\" + 0.010*\"population\" + 0.008*\"content\" + 0.008*\"per\" + 0.008*\"acknowledgements\" + 0.008*\"new\" + 0.007*\"name\" + 0.007*\"context\" + 0.007*\"york\" + 0.007*\"crime\" + 0.006*\"non\" + 0.006*\"state\" + 0.006*\"inspiration\" + 0.006*\"district\" + 0.006*\"contains\" + 0.006*\"census\"'),\n",
       " (5,\n",
       "  '0.014*\"instances\" + 0.010*\"cell\" + 0.008*\"information\" + 0.008*\"number\" + 0.007*\"group\" + 0.007*\"one\" + 0.007*\"column\" + 0.007*\"contains\" + 0.007*\"content\" + 0.006*\"activity\" + 0.006*\"use\" + 0.006*\"context\" + 0.006*\"body\" + 0.006*\"class\" + 0.005*\"time\" + 0.005*\"software\" + 0.005*\"acknowledgements\" + 0.005*\"set\" + 0.005*\"human\" + 0.005*\"learning\"'),\n",
       " (6,\n",
       "  '0.228*\"university\" + 0.038*\"state\" + 0.019*\"college\" + 0.011*\"california\" + 0.008*\"institute\" + 0.007*\"back\" + 0.007*\"new\" + 0.006*\"time\" + 0.006*\"com\" + 0.006*\"technology\" + 0.006*\"content\" + 0.006*\"north\" + 0.005*\"set\" + 0.005*\"context\" + 0.005*\"solar\" + 0.005*\"information\" + 0.005*\"may\" + 0.005*\"acknowledgements\" + 0.005*\"column\" + 0.005*\"lower\"'),\n",
       " (7,\n",
       "  '0.015*\"content\" + 0.014*\"context\" + 0.012*\"inspiration\" + 0.010*\"acknowledgements\" + 0.008*\"contains\" + 0.007*\"time\" + 0.007*\"others\" + 0.006*\"research\" + 0.006*\"price\" + 0.005*\"world\" + 0.005*\"2017\" + 0.005*\"help\" + 0.005*\"past\" + 0.005*\"used\" + 0.005*\"number\" + 0.005*\"use\" + 0.005*\"include\" + 0.005*\"see\" + 0.005*\"service\" + 0.005*\"different\"'),\n",
       " (8,\n",
       "  '0.014*\"number\" + 0.013*\"content\" + 0.011*\"context\" + 0.009*\"https\" + 0.008*\"use\" + 0.008*\"year\" + 0.008*\"contains\" + 0.008*\"kaggle\" + 0.007*\"acknowledgements\" + 0.007*\"files\" + 0.007*\"per\" + 0.006*\"information\" + 0.006*\"using\" + 0.006*\"day\" + 0.005*\"features\" + 0.005*\"inspiration\" + 0.005*\"com\" + 0.005*\"package\" + 0.005*\"kernel\" + 0.005*\"time\"'),\n",
       " (9,\n",
       "  '0.019*\"trained\" + 0.011*\"pre\" + 0.011*\"features\" + 0.010*\"time\" + 0.009*\"contains\" + 0.008*\"set\" + 0.008*\"models\" + 0.007*\"context\" + 0.007*\"accuracy\" + 0.007*\"use\" + 0.007*\"acknowledgements\" + 0.007*\"using\" + 0.006*\"content\" + 0.006*\"results\" + 0.006*\"image\" + 0.005*\"inspiration\" + 0.005*\"different\" + 0.005*\"like\" + 0.005*\"available\" + 0.005*\"deep\"')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics(num_topics=10,num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_names= [\"Social Media\",\n",
    "    \"Education\",\n",
    "    \"News and Sports\",\n",
    "    \"Web Resources\",\n",
    "    \"Demographics\",\n",
    "    \"Biology\",\n",
    "    \"Technology\",\n",
    "    \"Research\",\n",
    "    \"Data Analysis\",\n",
    "    \"Machine Learning\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background\n",
      "What can we say about the success of a movie before it is released? Are there certain companies (Pixar?) that have found a consistent formula? Given that major films costing over $100 million to produce can still flop, this question is more important than ever to the industry. Film aficionados might have different interests. Can we predict which films will be highly rated, whether or not they are a commercial success?\n",
      "This is a great place to start digging in to those questions, with data on the plot, cast, crew, budget, and revenues of several thousand films.\n",
      "Data Source Transfer Summary\n",
      "We (Kaggle) have removed the original version of this dataset per a DMCA takedown request from IMDB. In order to minimize the impact, we're replacing it with a similar set of films and data fields from The Movie Database (TMDb) in accordance with their terms of use. The bad news is that kernels built on the old dataset will most likely no longer work.\n",
      "The good news is that:\n",
      "You can port your existing kernels over with a bit of editing. This kernel offers functions and examples for doing so. You can also find a general introduction to the new format here.\n",
      "The new dataset contains full credits for both the cast and the crew, rather than just the first three actors.\n",
      "Actor and actresses are now listed in the order they appear in the credits. It's unclear what ordering the original dataset used; for the movies I spot checked it didn't line up with either the credits order or IMDB's stars order.\n",
      "The revenues appear to be more current. For example, IMDB's figures for Avatar seem to be from 2010 and understate the film's global revenues by over $2 billion.\n",
      "Some of the movies that we weren't able to port over (a couple of hundred) were just bad entries. For example, this IMDB entry has basically no accurate information at all. It lists Star Wars Episode VII as a documentary.\n",
      "Data Source Transfer Details\n",
      "Several of the new columns contain json. You can save a bit of time by porting the load data functions from this kernel.\n",
      "Even in simple fields like runtime may not be consistent across versions. For example, previous dataset shows the duration for Avatar's extended cut while TMDB shows the time for the original version.\n",
      "There's now a separate file containing the full credits for both the cast and crew.\n",
      "All fields are filled out by users so don't expect them to agree on keywords, genres, ratings, or the like.\n",
      "Your existing kernels will continue to render normally until they are re-run.\n",
      "If you are curious about how this dataset was prepared, the code to access TMDb's API is posted here.\n",
      "New columns:\n",
      "homepage\n",
      "id\n",
      "original_title\n",
      "overview\n",
      "popularity\n",
      "production_companies\n",
      "production_countries\n",
      "release_date\n",
      "spoken_languages\n",
      "status\n",
      "tagline\n",
      "vote_average\n",
      "Lost columns:\n",
      "actor_1_facebook_likes\n",
      "actor_2_facebook_likes\n",
      "actor_3_facebook_likes\n",
      "aspect_ratio\n",
      "cast_total_facebook_likes\n",
      "color\n",
      "content_rating\n",
      "director_facebook_likes\n",
      "facenumber_in_poster\n",
      "movie_facebook_likes\n",
      "movie_imdb_link\n",
      "num_critic_for_reviews\n",
      "num_user_for_reviews\n",
      "Open Questions About the Data\n",
      "There are some things we haven't had a chance to confirm about the new dataset. If you have any insights, please let us know in the forums!\n",
      "Are the budgets and revenues all in US dollars? Do they consistently show the global revenues?\n",
      "This dataset hasn't yet gone through a data quality analysis. Can you find any obvious corrections? For example, in the IMDb version it was necessary to treat values of zero in the budget field as missing. Similar findings would be very helpful to your fellow Kagglers! (It's probably a good idea to keep treating zeros as missing, with the caveat that missing budgets much more likely to have been from small budget films in the first place).\n",
      "Inspiration\n",
      "Can you categorize the films by type, such as animated or not? We don't have explicit labels for this, but it should be possible to build them from the crew's job titles.\n",
      "How sharp is the divide between major film studios and the independents? Do those two groups fall naturally out of a clustering analysis or is something more complicated going on?\n",
      "Acknowledgements\n",
      "This dataset was generated from The Movie Database API. This product uses the TMDb API but is not endorsed or certified by TMDb. Their API also provides access to data on many additional movies, actors and actresses, crew members, and TV shows. You can try it for yourself here.\n",
      "[[(0, 0.58470225), (2, 0.027201915), (5, 0.22022478), (7, 0.020959772), (8, 0.031769212), (9, 0.11345321)]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Social Media'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc = [df.loc[2, 'Description']]\n",
    "print(new_doc[0])\n",
    "\n",
    "doc_vectorized= vectorizer.transform(new_doc) # input param is list\n",
    "new_doc_corpus = gensim.matutils.Sparse2Corpus(doc_vectorized, documents_columns=False)\n",
    "doc_topics = ldamodel.get_document_topics(new_doc_corpus)\n",
    "print(list(doc_topics))\n",
    "\n",
    "def elicit_topic_name(doc_topics):    \n",
    "    return topics_names[np.squeeze(np.array(doc_topics))[:,1].argmax()]\n",
    "elicit_topic_name(doc_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "## Learn more\n",
    "</font>\n",
    "\n",
    "Latent Dirichlet allocation\n",
    "<br>\n",
    "https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation\n",
    "\n",
    "LDA Algorithm Description.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
