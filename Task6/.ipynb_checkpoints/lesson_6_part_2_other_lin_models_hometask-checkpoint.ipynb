{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home Task\n",
    "Use diabetes dataset (sklearn.datasets.load_diabetes) and apply\n",
    "\n",
    "Ridge;\n",
    "Lasso;\n",
    "Normal Equation;\n",
    "Polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "\n",
    "def get_X_y(features= None, verbose= False):\n",
    "    X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "    if features is None:\n",
    "        print ('Selecting all features')\n",
    "        \n",
    "    elif type(features) == int or (type(features) == list and len(features)==1):\n",
    "        print ('Selecting one feature: {}'.format(features))\n",
    "        X= X[:,features].reshape(-1,1) # single column \n",
    "    elif type(features) == list: \n",
    "        print ('Selecting features list: {}'.format(features))\n",
    "        X= X[:,features]\n",
    "    else: \n",
    "        print ('wrong format of parameter \"features\"')\n",
    "        return\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test=  train_test_split(X, y, random_state=2021)\n",
    "    if verbose:\n",
    "        print ('X_train.shape= ',X_train.shape)\n",
    "        print ('y_train.shape= ',y_train.shape)\n",
    "        print ('X_train [:5] = \\n{}'.format(X_train[:5]))\n",
    "        print ('y_train [:5] = \\n{}'.format(y_train[:5]))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting all features\n",
      "X_train.shape=  (331, 10)\n",
      "y_train.shape=  (331,)\n",
      "X_train [:5] = \n",
      "[[-0.06363517 -0.04464164 -0.03315126 -0.03321358  0.00118295  0.02405115\n",
      "  -0.02499266 -0.00259226 -0.02251217 -0.05906719]\n",
      " [ 0.01264814 -0.04464164 -0.02560657 -0.04009932 -0.03046397 -0.04515466\n",
      "   0.0780932  -0.0763945  -0.07212845  0.01134862]\n",
      " [ 0.03807591  0.05068012  0.00888341  0.04252958 -0.04284755 -0.02104223\n",
      "  -0.03971921 -0.00259226 -0.01811827  0.00720652]\n",
      " [-0.07816532  0.05068012  0.07786339  0.05285819  0.07823631  0.0644473\n",
      "   0.02655027 -0.00259226  0.04067226 -0.00936191]\n",
      " [-0.07453279 -0.04464164 -0.0105172  -0.00567061 -0.06623874 -0.0570543\n",
      "  -0.00290283 -0.03949338 -0.0425721  -0.0010777 ]]\n",
      "y_train [:5] = \n",
      "[214.  98. 127. 233. 168.]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test=  get_X_y(verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "R2 train score = 0.4227500042714355\n",
      "R2 test score = 0.4342970082842499\n",
      "b: 148.99988868218784, \n",
      "w= [  31.07135389  -67.81258571  284.12046397  158.3081174    25.34302859\n",
      "  -14.6316645  -130.28687824  116.41280432  239.50350188  108.52433481]\n"
     ]
    }
   ],
   "source": [
    "# Ridge\n",
    "\n",
    "ridge_reg=Ridge()\n",
    "ridge_reg.fit(X_train,y_train)\n",
    "regressor = ridge_reg\n",
    "print ('Ridge')\n",
    "print ('R2 train score =', regressor.score(X_train, y_train))\n",
    "print ('R2 test score =', regressor.score(X_test, y_test))\n",
    "print ('b: {}, \\nw= {}'.format(regressor.intercept_, regressor.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso\n",
      "R2 train score = 0.36602010243711314\n",
      "R2 test score = 0.3392074106660582\n",
      "b: 149.4852586610367, \n",
      "w= [  0.          -0.         379.30470419   0.           0.\n",
      "   0.          -0.           0.         317.42763802   0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "\n",
    "lasso_reg=Lasso()\n",
    "lasso_reg.fit(X_train,y_train)\n",
    "regressor = lasso_reg\n",
    "print ('Lasso')\n",
    "print ('R2 train score =', regressor.score(X_train, y_train))\n",
    "print ('R2 test score =', regressor.score(X_test, y_test))\n",
    "print ('b: {}, \\nw= {}'.format(regressor.intercept_, regressor.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving linear regression using normal equation...\n",
      "b: 148.99287782145046, \n",
      "w= [[ -19.68524788 -240.18043072  557.91466379  251.50090048 -500.39623377\n",
      "   275.58122739  -11.60794591  154.01479032  651.17035619   77.51258452]]\n",
      "Predicting using normal equation...\n",
      "R2 train score = 0.5073702774872662\n",
      "R2 test score = 0.528173969826651\n"
     ]
    }
   ],
   "source": [
    "# Normal Equation\n",
    "\n",
    "m,n = X_train.shape\n",
    "# adding 1-column\n",
    "X_train_ext =  np.c_[(np.ones((m,1)),X_train)]\n",
    "assert (X_train_ext.shape== (m,n+1))\n",
    "\n",
    "print ('Solving linear regression using normal equation...')\n",
    "\n",
    "params = np.linalg.pinv (X_train_ext.T @ X_train_ext ) @ X_train_ext.T @ y_train\n",
    "\n",
    "\n",
    "params = np.linalg.pinv (X_train_ext.T @ X_train_ext ) @ X_train_ext.T @ y_train\n",
    "b = params[0]\n",
    "w=params[1:].reshape (1,-1) \n",
    "print ('b: {}, \\nw= {}'.format(b,w)) \n",
    "\n",
    "print ('Predicting using normal equation...')\n",
    "\n",
    "z_train= b+ X_train @ w.T\n",
    "z_test= b+ X_test @ w.T\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print ('R2 train score =',  r2_score(y_train,z_train))\n",
    "print ('R2 test score =', r2_score(y_test,z_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape=  (331, 10)\n",
      "X_train_poly.shape=  (331, 65)\n",
      "Polynomial + Linear Regression\n",
      "R2 train score = 0.6207797301635396\n",
      "R2 test score = 0.34719901380574214\n",
      "b: 56.79525186375287, \n",
      "w= [ 1.06168923e+02 -2.77265262e+02  5.11299899e+02  2.51497433e+02\n",
      " -1.80092300e+04  1.57192074e+04  6.57373097e+03  1.74001071e+02\n",
      "  6.49554697e+03  9.66785599e+01  2.78256324e+03  3.85252924e+03\n",
      " -1.54319287e+02  9.33782637e+02  7.84052092e+03 -1.10754021e+04\n",
      " -1.11039929e+03  2.01320959e+03  1.35182836e+03 -1.10168958e+03\n",
      " -1.67426138e+00  2.29713538e+03  2.56866007e+02 -6.55374965e+02\n",
      "  1.80613963e+03  1.34943461e+02 -6.93340553e+03  1.68125028e+03\n",
      "  1.60066363e+03  1.15273617e+03  3.13892761e+03 -8.12973306e+02\n",
      "  5.98607631e+02  9.01138185e+02 -1.26003138e+03  3.87472697e+02\n",
      "  7.84628596e+02 -3.71765740e+02  1.50825980e+04 -1.23431929e+04\n",
      " -3.95041730e+03  3.06050706e+03 -5.21923360e+03 -2.22836579e+03\n",
      "  8.86560173e+04 -1.15193867e+05 -7.26859339e+04 -3.64067602e+04\n",
      " -2.75141402e+04 -4.86607913e+03  3.74714287e+04  4.50805009e+04\n",
      "  2.00155986e+04  1.30646092e+04  9.22691891e+02  1.31884288e+04\n",
      "  9.60589503e+03  1.16197737e+04  1.07437093e+04  3.90627791e+03\n",
      "  9.13719911e+03  8.77609930e+03  2.95419005e+04  3.13701898e+03\n",
      "  1.70552822e+03]\n"
     ]
    }
   ],
   "source": [
    "poly= PolynomialFeatures(degree=2,include_bias=False) # default is True means to return the first feature of all 1 as for degree 0 \n",
    "X_train_poly= poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "print ('X_train.shape= ',X_train.shape)\n",
    "print ('X_train_poly.shape= ',X_train_poly.shape)\n",
    "# X_train_poly[:5]\n",
    "poly_lin_reg = LinearRegression().fit (X_train_poly,y_train)\n",
    "regressor = poly_lin_reg\n",
    "print ('Polynomial + Linear Regression')\n",
    "print ('R2 train score =', regressor.score(X_train_poly, y_train))\n",
    "print ('R2 test score =', regressor.score(X_test_poly, y_test))\n",
    "print ('b: {}, \\nw= {}'.format(regressor.intercept_, regressor.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
